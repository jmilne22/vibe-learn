conceptLinks:
  Fan-Out Fan-In: fan-out-fan-in
  Worker Pools: worker-pools
  Select: select-and-multiplexing
  Context: context-cancellation-and-timeouts
  Rate Limiting: rate-limiting
sharedContent: {}
variants:
  warmups:
    - id: warmup_1
      concept: Select
      variants:
        - id: v1
          title: Select with Timeout
          description: >-
            Write a function that reads from a channel with a 500ms timeout. If data arrives, return it. If timeout
            fires, return an error.
          hints:
            - >-
              Use <code>select</code> with <code>case val := <-ch</code> and <code>case
              <-time.After(500*time.Millisecond)</code>
          solution: |-
            func readWithTimeout(ch <-chan string) (string, error) {
                select {
                case val := <-ch:
                    return val, nil
                case <-time.After(500 * time.Millisecond):
                    return "", fmt.Errorf("timeout")
                }
            }
        - id: v2
          title: Non-Blocking Send
          description: >-
            Write a function <code>trySend(ch chan<- string, val string) bool</code> that sends val on ch without
            blocking. Returns true if sent, false if channel is full.
          hints:
            - Use <code>select</code> with <code>case ch <- val</code> and <code>default</code>
          solution: |-
            func trySend(ch chan<- string, val string) bool {
                select {
                case ch <- val:
                    return true
                default:
                    return false
                }
            }
    - id: warmup_2
      concept: Context
      variants:
        - id: v1
          title: Context with Timeout
          description: >-
            Create a context with 2-second timeout. Write a function that simulates work by sleeping for a given
            duration, checking <code>ctx.Done()</code>. Call it with 1s (succeeds) and 3s (times out).
          hints:
            - Use <code>context.WithTimeout(context.Background(), 2*time.Second)</code>
            - "Check: <code>select { case <-ctx.Done(): return ctx.Err(); case <-time.After(d): return nil }</code>"
          solution: |-
            func doWork(ctx context.Context, duration time.Duration) error {
                select {
                case <-ctx.Done():
                    return ctx.Err()
                case <-time.After(duration):
                    return nil
                }
            }

            ctx, cancel := context.WithTimeout(context.Background(), 2*time.Second)
            defer cancel()
            fmt.Println(doWork(ctx, 1*time.Second))  // nil
            fmt.Println(doWork(ctx, 3*time.Second))  // context deadline exceeded
        - id: v2
          title: Cancellable Loop
          description: >-
            Write a function <code>processUntilCancelled(ctx context.Context, items []string) int</code> that processes
            items one at a time (print each), checking for context cancellation before each item. Return how many were
            processed.
          hints:
            - "Check <code>select { case <-ctx.Done(): return count; default: }</code> before processing"
          solution: |-
            func processUntilCancelled(ctx context.Context, items []string) int {
                count := 0
                for _, item := range items {
                    select {
                    case <-ctx.Done():
                        return count
                    default:
                    }
                    fmt.Println("processing:", item)
                    count++
                }
                return count
            }
    - id: warmup_3
      concept: Worker Pools
      variants:
        - id: v1
          title: Simple Worker Pool
          description: >-
            Write a worker pool with 3 workers processing strings from a jobs channel. Each worker converts the string
            to uppercase and sends to a results channel. Process 10 jobs and collect results.
          hints:
            - "Workers: <code>for job := range jobs { results <- strings.ToUpper(job) }</code>"
            - Use WaitGroup to know when to close results
          solution: |-
            jobs := make(chan string, 10)
            results := make(chan string, 10)

            var wg sync.WaitGroup
            for w := 0; w < 3; w++ {
                wg.Add(1)
                go func() {
                    defer wg.Done()
                    for job := range jobs {
                        results <- strings.ToUpper(job)
                    }
                }()
            }

            for i := 0; i < 10; i++ {
                jobs <- fmt.Sprintf("job-%d", i)
            }
            close(jobs)

            go func() {
                wg.Wait()
                close(results)
            }()

            for r := range results {
                fmt.Println(r)
            }
    - id: warmup_4
      concept: Rate Limiting
      variants:
        - id: v1
          title: Ticker Rate Limiter
          description: >-
            Write code that processes 10 items at a rate of 5 per second using <code>time.NewTicker</code>. Print each
            item with its timestamp to verify the rate.
          hints:
            - "Ticker interval: <code>200 * time.Millisecond</code> for 5/sec"
            - Wait on <code><-ticker.C</code> before each item
          solution: |-
            ticker := time.NewTicker(200 * time.Millisecond)
            defer ticker.Stop()

            start := time.Now()
            for i := 0; i < 10; i++ {
                <-ticker.C
                fmt.Printf("item %d at %v\n", i, time.Since(start).Round(time.Millisecond))
            }
  challenges:
    - id: challenge_1
      block: 1
      difficulty: 2
      concept: Worker Pools
      variants:
        - id: v1
          title: Config Validator Pool
          description: >-
            Write a worker pool that validates config files concurrently. <code>validateConfigs(paths []string, workers
            int) map[string]error</code>. Workers read paths from a jobs channel, validate each (simulate: error if
            filename contains 'bad'), and send results. Collect into a map of path→error (nil for valid).
          functionSignature: func validateConfigs(paths []string, workers int) map[string]error
          difficulty: 1
          testCases:
            - input: validateConfigs([]string{"good.yaml", "bad.yaml", "ok.yaml"}, 2)
              output: map[good.yaml:<nil> bad.yaml:error ok.yaml:<nil>]
          hints:
            - title: Think about it
              content: Jobs channel sends paths. Workers validate and send result structs. Main collects into a map.
            - title: Hint
              content: >-
                Result struct: <code>{Path string; Err error}</code>. Workers range over jobs, send results. Main
                collects len(paths) results.
          solution: |-
            type valResult struct {
                Path string
                Err  error
            }

            func validateConfigs(paths []string, workers int) map[string]error {
                jobs := make(chan string, len(paths))
                results := make(chan valResult, len(paths))

                var wg sync.WaitGroup
                for w := 0; w < workers; w++ {
                    wg.Add(1)
                    go func() {
                        defer wg.Done()
                        for path := range jobs {
                            var err error
                            if strings.Contains(path, "bad") {
                                err = fmt.Errorf("validation failed: %s", path)
                            }
                            results <- valResult{Path: path, Err: err}
                        }
                    }()
                }

                for _, p := range paths {
                    jobs <- p
                }
                close(jobs)

                go func() {
                    wg.Wait()
                    close(results)
                }()

                out := make(map[string]error)
                for r := range results {
                    out[r.Path] = r.Err
                }
                return out
            }
          annotations:
            - type: pattern
              label: Worker pool
              text: Jobs channel → N workers → results channel. The fundamental concurrent processing pattern in Go.
            - type: idiom
              label: Close coordination
              text: Close jobs after sending. WaitGroup + closer goroutine closes results after all workers finish.
        - id: v2
          title: Concurrent API Fetcher
          description: >-
            Write <code>fetchAll(ctx context.Context, urls []string, maxConcurrent int) ([]Response, error)</code>.
            Fetch URLs concurrently with bounded concurrency. If context is cancelled, stop launching new fetches.
            Return results in any order. Cancel everything on first error.
          functionSignature: func fetchAll(ctx context.Context, urls []string, maxConcurrent int) ([]Response, error)
          difficulty: 2
          testCases:
            - input: fetchAll(ctx, urls, 3) // all succeed
              output: ([]Response{...}, nil)
            - input: fetchAll(cancelledCtx, urls, 3)
              output: (nil, context.Canceled)
          hints:
            - title: Think about it
              content: >-
                Semaphore for bounded concurrency. Context for cancellation. First error cancels everything via a
                derived context.
            - title: Hint
              content: >-
                Create a derived context with <code>context.WithCancel(ctx)</code>. On first error, call cancel.
                Semaphore: <code>make(chan struct{}, maxConcurrent)</code>.
          solution: |-
            type Response struct {
                URL    string
                Status int
                Err    error
            }

            func fetchAll(ctx context.Context, urls []string, maxConcurrent int) ([]Response, error) {
                ctx, cancel := context.WithCancel(ctx)
                defer cancel()

                sem := make(chan struct{}, maxConcurrent)
                results := make(chan Response, len(urls))

                var wg sync.WaitGroup
                for _, u := range urls {
                    select {
                    case <-ctx.Done():
                        break
                    case sem <- struct{}{}:
                    }
                    wg.Add(1)
                    go func(url string) {
                        defer wg.Done()
                        defer func() { <-sem }()
                        req, _ := http.NewRequestWithContext(ctx, "GET", url, nil)
                        resp, err := http.DefaultClient.Do(req)
                        if err != nil {
                            results <- Response{URL: url, Err: err}
                            cancel()
                            return
                        }
                        resp.Body.Close()
                        results <- Response{URL: url, Status: resp.StatusCode}
                    }(u)
                }

                go func() {
                    wg.Wait()
                    close(results)
                }()

                var all []Response
                for r := range results {
                    if r.Err != nil {
                        return nil, r.Err
                    }
                    all = append(all, r)
                }
                return all, nil
            }
          annotations:
            - type: pattern
              label: Cancel on first error
              text: Derive a context with cancel. On error, call cancel() to stop all in-flight work.
            - type: interview
              label: Bounded fetch
              text: This combines semaphore, context, and error propagation — a frequent Go systems interview question.
        - id: v3
          title: Pipeline with Fan-Out Workers
          description: >-
            Build a 3-stage pipeline: Stage 1 generates file paths. Stage 2 fans out to N workers that read and validate
            files. Stage 3 collects results and produces a summary. Use context for cancellation. Write
            <code>lintPipeline(ctx context.Context, root string, workers int) (Summary, error)</code>.
          functionSignature: func lintPipeline(ctx context.Context, root string, workers int) (Summary, error)
          difficulty: 3
          testCases:
            - input: lintPipeline(ctx, "./configs", 4)
              output: Summary{Total:10, Valid:8, Invalid:2}
          hints:
            - title: Think about it
              content: >-
                Stage 1 walks the directory and sends paths to a channel. Stage 2 has N workers reading from that
                channel. Stage 3 aggregates results.
            - title: Hint
              content: >-
                Stage 1: goroutine with WalkDir, sends to paths channel, closes it. Stage 2: N workers range over paths,
                send LintResult to results. Stage 3: range over results, count valid/invalid.
          solution: |-
            type LintResult struct {
                Path  string
                Valid bool
                Err   string
            }
            type Summary struct {
                Total, Valid, Invalid int
            }

            func lintPipeline(ctx context.Context, root string, workers int) (Summary, error) {
                paths := make(chan string)
                go func() {
                    defer close(paths)
                    filepath.WalkDir(root, func(p string, d fs.DirEntry, err error) error {
                        if err != nil || d.IsDir() {
                            return err
                        }
                        if filepath.Ext(p) == ".yaml" {
                            select {
                            case paths <- p:
                            case <-ctx.Done():
                                return ctx.Err()
                            }
                        }
                        return nil
                    })
                }()

                results := make(chan LintResult)
                var wg sync.WaitGroup
                for i := 0; i < workers; i++ {
                    wg.Add(1)
                    go func() {
                        defer wg.Done()
                        for path := range paths {
                            data, err := os.ReadFile(path)
                            if err != nil {
                                results <- LintResult{Path: path, Err: err.Error()}
                                continue
                            }
                            var m map[string]any
                            if err := yaml.Unmarshal(data, &m); err != nil {
                                results <- LintResult{Path: path, Err: err.Error()}
                            } else {
                                results <- LintResult{Path: path, Valid: true}
                            }
                        }
                    }()
                }
                go func() {
                    wg.Wait()
                    close(results)
                }()

                var s Summary
                for r := range results {
                    s.Total++
                    if r.Valid {
                        s.Valid++
                    } else {
                        s.Invalid++
                    }
                }
                return s, nil
            }
          annotations:
            - type: pattern
              label: Multi-stage pipeline
              text: >-
                Generate → Process (fan-out) → Aggregate. Each stage connected by channels. This is production-grade
                concurrent architecture.
            - type: interview
              label: System design
              text: Building concurrent pipelines with bounded workers and cancellation is asked in senior Go interviews.
            - type: idiom
              label: WalkDir + channels
              text: WalkDir in a goroutine sending to a channel is the standard pattern for concurrent directory processing.
    - id: challenge_2
      block: 2
      difficulty: 2
      concept: Context
      variants:
        - id: v1
          title: Context-Aware Health Checker
          description: >-
            Write <code>checkHealthWithTimeout(endpoints []string, timeout time.Duration) []HealthResult</code>. Check
            all endpoints concurrently. The entire operation must complete within the timeout. Use a single context. If
            timeout fires, return whatever results were collected so far.
          functionSignature: func checkHealthWithTimeout(endpoints []string, timeout time.Duration) []HealthResult
          difficulty: 1
          testCases:
            - input: checkHealthWithTimeout(endpoints, 5*time.Second) // all fast
              output: all results
            - input: checkHealthWithTimeout(endpoints, 10*time.Millisecond) // one slow
              output: partial results
          hints:
            - title: Think about it
              content: Create a context with timeout. Pass it to all goroutines. Collect results until timeout or all done.
            - title: Hint
              content: >-
                Use a buffered results channel. After launching goroutines, collect with select: <code>case r :=
                <-results</code> or <code>case <-ctx.Done()</code>.
          solution: |-
            type HealthResult struct {
                URL     string
                Healthy bool
            }

            func checkHealthWithTimeout(endpoints []string, timeout time.Duration) []HealthResult {
                ctx, cancel := context.WithTimeout(context.Background(), timeout)
                defer cancel()

                results := make(chan HealthResult, len(endpoints))
                for _, ep := range endpoints {
                    go func(url string) {
                        req, _ := http.NewRequestWithContext(ctx, "GET", url, nil)
                        resp, err := http.DefaultClient.Do(req)
                        if err != nil {
                            results <- HealthResult{URL: url, Healthy: false}
                            return
                        }
                        resp.Body.Close()
                        results <- HealthResult{URL: url, Healthy: resp.StatusCode == 200}
                    }(ep)
                }

                var all []HealthResult
                for i := 0; i < len(endpoints); i++ {
                    select {
                    case r := <-results:
                        all = append(all, r)
                    case <-ctx.Done():
                        return all
                    }
                }
                return all
            }
          annotations:
            - type: pattern
              label: Deadline collection
              text: Collect as many results as possible before the deadline. Return partial results instead of failing.
            - type: idiom
              label: Context in requests
              text: >-
                NewRequestWithContext propagates the timeout to the HTTP client. Cancelled context cancels in-flight
                requests.
        - id: v2
          title: Graceful Shutdown Handler
          description: >-
            Write a function that starts a simulated service (processes jobs from a channel in a loop). On SIGINT
            (simulated via context cancellation), it should: stop accepting new jobs, finish the current job, and return
            the count of processed jobs. Use <code>select</code> with <code>ctx.Done()</code>.
          functionSignature: func runService(ctx context.Context, jobs <-chan string) int
          difficulty: 2
          testCases:
            - input: runService(ctx, jobs) // 5 jobs then cancel
              output: "5"
            - input: runService(cancelledCtx, jobs)
              output: "0"
          hints:
            - title: Think about it
              content: Select between jobs and ctx.Done(). When cancelled, return immediately. Count processed jobs.
            - title: Hint
              content: >-
                Loop with select: <code>case job, ok := <-jobs</code> (process), <code>case <-ctx.Done()</code> (return
                count). Check <code>!ok</code> for closed channel.
          solution: |-
            func runService(ctx context.Context, jobs <-chan string) int {
                count := 0
                for {
                    select {
                    case <-ctx.Done():
                        fmt.Println("shutting down, processed", count)
                        return count
                    case job, ok := <-jobs:
                        if !ok {
                            return count
                        }
                        fmt.Println("processing:", job)
                        count++
                    }
                }
            }
          annotations:
            - type: pattern
              label: Service loop
              text: >-
                for + select is the core pattern for long-running Go services. Handle jobs, ticks, and shutdown in one
                loop.
            - type: interview
              label: Graceful shutdown
              text: Every Go service needs graceful shutdown. K8s sends SIGTERM, you need to drain in-flight work.
        - id: v3
          title: Cascading Cancellation
          description: >-
            Build a 3-level call chain: <code>handler → service → store</code>. The handler creates a context with 5s
            timeout. The service derives a child context with 2s timeout for each store call. If the store is slow, the
            service should cancel and try a fallback. If the handler times out, everything stops. Demonstrate with
            simulated delays.
          functionSignature: func handler(ctx context.Context) (string, error)
          difficulty: 3
          testCases:
            - input: handler(ctx) // store responds in 1s
              output: ("data from store", nil)
            - input: handler(ctx) // store slow, fallback works
              output: ("data from fallback", nil)
            - input: handler(cancelledCtx)
              output: ("", context error)
          hints:
            - title: Think about it
              content: >-
                Handler sets overall timeout. Service creates child context for store call. If store times out, service
                tries fallback with remaining time.
            - title: Hint
              content: >-
                Service: <code>storeCtx, cancel := context.WithTimeout(ctx, 2*time.Second)</code>. Try store. If
                deadline exceeded, try fallback with the parent ctx (which still has time).
          solution: |-
            func store(ctx context.Context) (string, error) {
                select {
                case <-ctx.Done():
                    return "", ctx.Err()
                case <-time.After(3 * time.Second): // simulated slow
                    return "data from store", nil
                }
            }

            func fallback(ctx context.Context) (string, error) {
                select {
                case <-ctx.Done():
                    return "", ctx.Err()
                case <-time.After(500 * time.Millisecond):
                    return "data from fallback", nil
                }
            }

            func service(ctx context.Context) (string, error) {
                storeCtx, cancel := context.WithTimeout(ctx, 2*time.Second)
                defer cancel()

                result, err := store(storeCtx)
                if err == nil {
                    return result, nil
                }
                fmt.Println("store timed out, trying fallback")
                return fallback(ctx) // use parent context — may still have time
            }

            func handler(ctx context.Context) (string, error) {
                ctx, cancel := context.WithTimeout(ctx, 5*time.Second)
                defer cancel()
                return service(ctx)
            }
          annotations:
            - type: pattern
              label: Context hierarchy
              text: >-
                Parent timeout > child timeout. Child can timeout without killing the parent, allowing fallback
                strategies.
            - type: interview
              label: Context design
              text: Understanding context hierarchy and cascading cancellation is a senior Go interview topic.
            - type: gotcha
              label: Always defer cancel
              text: >-
                Every WithTimeout/WithCancel must have a deferred cancel. Forgetting leaks goroutines in the context
                tree.
