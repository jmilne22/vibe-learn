conceptLinks:
  Namespaces: linux-namespaces-from-go
  Process Isolation: process-isolation
  Filesystem Isolation: filesystem-isolation
  Cgroups: cgroups-resource-limits
sharedContent: {}
variants:
  warmups:
    - id: warmup_1
      concept: Namespaces
      variants:
        - id: v1
          title: Namespace Flags
          description: >-
            Write a function that creates an <code>exec.Cmd</code> to run a command in new PID and UTS namespaces using
            <code>SysProcAttr.Cloneflags</code>. Return the configured Cmd.
          hints:
            - >-
              Set <code>cmd.SysProcAttr = &syscall.SysProcAttr{Cloneflags: syscall.CLONE_NEWPID |
              syscall.CLONE_NEWUTS}</code>
          solution: |-
            func newIsolatedCmd(command string, args ...string) *exec.Cmd {
                cmd := exec.Command(command, args...)
                cmd.SysProcAttr = &syscall.SysProcAttr{
                    Cloneflags: syscall.CLONE_NEWPID | syscall.CLONE_NEWUTS,
                }
                cmd.Stdin = os.Stdin
                cmd.Stdout = os.Stdout
                cmd.Stderr = os.Stderr
                return cmd
            }
        - id: v2
          title: Re-exec Pattern
          description: >-
            Write the <code>main()</code> skeleton for the re-exec pattern: if <code>os.Args[1]</code> is
            <code>"run"</code>, call parent(). If <code>"child"</code>, call child(). This is how container runtimes
            separate namespace setup from container execution.
          hints:
            - Use a switch on <code>os.Args[1]</code>. Parent re-execs with <code>/proc/self/exe child</code>
          solution: |-
            func main() {
                if len(os.Args) < 2 {
                    log.Fatal("usage: container run <cmd>")
                }
                switch os.Args[1] {
                case "run":
                    parent()
                case "child":
                    child()
                default:
                    log.Fatalf("unknown command: %s", os.Args[1])
                }
            }
    - id: warmup_2
      concept: Cgroups
      variants:
        - id: v1
          title: Set Memory Limit
          description: >-
            Write a function that creates a cgroup v2 directory and sets a memory limit by writing to
            <code>memory.max</code>. Add the current process to the cgroup by writing its PID to
            <code>cgroup.procs</code>.
          hints:
            - Use <code>os.MkdirAll</code> for the cgroup dir, <code>os.WriteFile</code> for memory.max and cgroup.procs
            - Write the byte count as a string to memory.max, write <code>os.Getpid()</code> to cgroup.procs
          solution: |-
            func setCgroupMemory(cgroupPath string, limitBytes int64) error {
                if err := os.MkdirAll(cgroupPath, 0755); err != nil {
                    return err
                }
                if err := os.WriteFile(
                    filepath.Join(cgroupPath, "memory.max"),
                    []byte(fmt.Sprintf("%d", limitBytes)), 0644,
                ); err != nil {
                    return err
                }
                return os.WriteFile(
                    filepath.Join(cgroupPath, "cgroup.procs"),
                    []byte(fmt.Sprintf("%d", os.Getpid())), 0644,
                )
            }
        - id: v2
          title: Read Cgroup Stats
          description: >-
            Write a function that reads current memory usage from a cgroup's <code>memory.current</code> file and
            returns it as <code>int64</code> bytes.
          hints:
            - Use <code>os.ReadFile</code>, <code>strings.TrimSpace</code>, then <code>strconv.ParseInt</code>
          solution: |-
            func readMemoryUsage(cgroupPath string) (int64, error) {
                data, err := os.ReadFile(filepath.Join(cgroupPath, "memory.current"))
                if err != nil {
                    return 0, err
                }
                return strconv.ParseInt(strings.TrimSpace(string(data)), 10, 64)
            }
  challenges:
    - id: challenge_1
      block: 1
      difficulty: 1
      concept: Cgroups
      variants:
        - id: v1
          title: Cgroup Manager
          description: >-
            Write a <code>CgroupManager</code> struct with methods to set memory limit, CPU limit, and PID limit for a
            cgroup. Include a <code>Cleanup()</code> method that removes the cgroup directory.
          functionSignature: type CgroupManager struct { path string }
          difficulty: 1
          testCases:
            - input: mgr.SetMemory(256 * 1024 * 1024)
              output: writes 268435456 to memory.max
            - input: mgr.SetCPU(50)
              output: writes "50000 100000" to cpu.max
            - input: mgr.SetPids(64)
              output: writes 64 to pids.max
            - input: mgr.Cleanup()
              output: removes the cgroup directory
          hints:
            - title: Think about it
              content: What's the format for cpu.max? How do you convert a percentage to quota/period?
            - title: Hint
              content: >-
                cpu.max format is "quota period" in microseconds. 50% = "50000 100000". Use os.WriteFile for each limit
                file. Cleanup with os.Remove.
          solution: |-
            type CgroupManager struct {
                path string
            }

            func NewCgroupManager(name string) (*CgroupManager, error) {
                p := filepath.Join("/sys/fs/cgroup", name)
                if err := os.MkdirAll(p, 0755); err != nil {
                    return nil, err
                }
                return &CgroupManager{path: p}, nil
            }

            func (m *CgroupManager) SetMemory(bytes int64) error {
                return os.WriteFile(filepath.Join(m.path, "memory.max"),
                    []byte(fmt.Sprintf("%d", bytes)), 0644)
            }

            func (m *CgroupManager) SetCPU(percent int) error {
                period := 100000
                quota := period * percent / 100
                return os.WriteFile(filepath.Join(m.path, "cpu.max"),
                    []byte(fmt.Sprintf("%d %d", quota, period)), 0644)
            }

            func (m *CgroupManager) SetPids(max int) error {
                return os.WriteFile(filepath.Join(m.path, "pids.max"),
                    []byte(fmt.Sprintf("%d", max)), 0644)
            }

            func (m *CgroupManager) AddProcess(pid int) error {
                return os.WriteFile(filepath.Join(m.path, "cgroup.procs"),
                    []byte(fmt.Sprintf("%d", pid)), 0644)
            }

            func (m *CgroupManager) Cleanup() error {
                return os.Remove(m.path)
            }
          annotations:
            - type: pattern
              label: Struct API Wrapper
              text: Struct with methods wrapping filesystem operations — clean API over cgroup v2 files
            - type: stdlib
              label: Cgroup File Ops
              text: os.WriteFile and filepath.Join are all you need for cgroup management
        - id: v2
          title: Container Config Parser
          description: >-
            Write a function that parses a container config (JSON) with fields: <code>command</code> (string),
            <code>hostname</code> (string), <code>memory_mb</code> (int), <code>cpu_percent</code> (int),
            <code>max_pids</code> (int), <code>rootfs</code> (string). Validate that memory is 1-8192MB, CPU is 1-100%,
            and max_pids is 1-4096. Return the config or an error listing all violations.
          functionSignature: func parseContainerConfig(data []byte) (*ContainerConfig, error)
          difficulty: 2
          testCases:
            - input: "valid config: 256MB, 50% CPU, 64 pids"
              output: (*ContainerConfig, nil)
            - input: "memory: 0, cpu: 200"
              output: error listing both violations
            - input: invalid JSON
              output: error
          hints:
            - title: Think about it
              content: Should you return on the first validation error, or collect all errors?
            - title: Hint
              content: >-
                Collect all errors in a slice. After checking all fields, join them into one error if any exist. This
                gives the user complete feedback.
          solution: |-
            type ContainerConfig struct {
                Command    string `json:"command"`
                Hostname   string `json:"hostname"`
                MemoryMB   int    `json:"memory_mb"`
                CPUPercent int    `json:"cpu_percent"`
                MaxPids    int    `json:"max_pids"`
                Rootfs     string `json:"rootfs"`
            }

            func parseContainerConfig(data []byte) (*ContainerConfig, error) {
                var cfg ContainerConfig
                if err := json.Unmarshal(data, &cfg); err != nil {
                    return nil, fmt.Errorf("invalid JSON: %w", err)
                }
                var errs []string
                if cfg.Command == "" {
                    errs = append(errs, "command is required")
                }
                if cfg.MemoryMB < 1 || cfg.MemoryMB > 8192 {
                    errs = append(errs, "memory_mb must be 1-8192")
                }
                if cfg.CPUPercent < 1 || cfg.CPUPercent > 100 {
                    errs = append(errs, "cpu_percent must be 1-100")
                }
                if cfg.MaxPids < 1 || cfg.MaxPids > 4096 {
                    errs = append(errs, "max_pids must be 1-4096")
                }
                if len(errs) > 0 {
                    return nil, fmt.Errorf("validation: %s", strings.Join(errs, "; "))
                }
                return &cfg, nil
            }
          annotations:
            - type: pattern
              label: Collect All Errors
              text: Collect all validation errors before returning — gives complete feedback in one pass
            - type: idiom
              label: Parse Then Validate
              text: Parse then validate — separate concerns for clarity
        - id: v3
          title: Container Lifecycle Manager
          description: >-
            Build a <code>Container</code> struct that manages the full lifecycle: configure namespaces, set up cgroups,
            prepare the filesystem, run the command, and clean up. Include a <code>Start()</code> that runs the
            container and a <code>Stop()</code> that sends SIGTERM then SIGKILL after a grace period.
          functionSignature: |-
            type Container struct { ... }
            func NewContainer(cfg ContainerConfig) *Container
            func (c *Container) Start() error
            func (c *Container) Stop(gracePeriod time.Duration) error
          difficulty: 3
          testCases:
            - input: NewContainer(cfg).Start()
              output: process running with namespaces and cgroup limits
            - input: container.Stop(5 * time.Second)
              output: SIGTERM, wait, SIGKILL if needed
          hints:
            - title: Think about it
              content: >-
                How do you track the running process so Stop() can signal it? What cleanup is needed even if the process
                exits abnormally?
            - title: Hint
              content: >-
                Store the *exec.Cmd and its Process in the struct. Start() uses cmd.Start() (not Run, so it doesn't
                block). Stop() sends SIGTERM, starts a timer, and sends SIGKILL if the process doesn't exit. Use defer
                for cgroup cleanup.
          solution: |-
            type Container struct {
                cfg     ContainerConfig
                cmd     *exec.Cmd
                cgroup  *CgroupManager
                done    chan struct{}
            }

            func NewContainer(cfg ContainerConfig) *Container {
                return &Container{cfg: cfg, done: make(chan struct{})}
            }

            func (c *Container) Start() error {
                cg, err := NewCgroupManager(c.cfg.Hostname)
                if err != nil {
                    return err
                }
                c.cgroup = cg
                cg.SetMemory(int64(c.cfg.MemoryMB) * 1024 * 1024)
                cg.SetCPU(c.cfg.CPUPercent)
                cg.SetPids(c.cfg.MaxPids)

                c.cmd = exec.Command("/proc/self/exe", "child", c.cfg.Command)
                c.cmd.SysProcAttr = &syscall.SysProcAttr{
                    Cloneflags: syscall.CLONE_NEWPID | syscall.CLONE_NEWUTS | syscall.CLONE_NEWNS,
                }
                c.cmd.Stdout = os.Stdout
                c.cmd.Stderr = os.Stderr

                if err := c.cmd.Start(); err != nil {
                    c.cgroup.Cleanup()
                    return err
                }
                cg.AddProcess(c.cmd.Process.Pid)

                go func() {
                    c.cmd.Wait()
                    close(c.done)
                }()
                return nil
            }

            func (c *Container) Stop(grace time.Duration) error {
                c.cmd.Process.Signal(syscall.SIGTERM)
                select {
                case <-c.done:
                case <-time.After(grace):
                    c.cmd.Process.Kill()
                    <-c.done
                }
                return c.cgroup.Cleanup()
            }
          annotations:
            - type: pattern
              label: Graceful Shutdown
              text: "Lifecycle management: Start/Stop with graceful shutdown mirrors how kubelet manages containers"
            - type: interview
              label: Lifecycle Design
              text: >-
                Designing a container lifecycle manager demonstrates systems thinking — a strong senior Go interview
                topic
            - type: gotcha
              label: Start vs Run
              text: Use cmd.Start() not cmd.Run() — Run blocks until the process exits, Start returns immediately
