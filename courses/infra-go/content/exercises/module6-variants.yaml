conceptLinks:
  Goroutines: goroutines-lightweight-threads
  Channels: channels-communication
  WaitGroups: waitgroups-knowing-when-its-done
  Concurrent Patterns: your-first-concurrent-pattern
sharedContent: {}
variants:
  warmups:
    - id: warmup_1
      concept: Goroutines
      variants:
        - id: v1
          title: Launch and Wait
          description: >-
            Launch 5 goroutines that each print <code>"worker N started"</code>. Use a <code>sync.WaitGroup</code> to
            wait for all of them before printing <code>"all done"</code>.
          hints:
            - Call <code>wg.Add(1)</code> before each <code>go func</code>
            - Use <code>defer wg.Done()</code> as the first line in each goroutine
          solution: |-
            var wg sync.WaitGroup
            for i := 0; i < 5; i++ {
                wg.Add(1)
                go func(id int) {
                    defer wg.Done()
                    fmt.Printf("worker %d started\n", id)
                }(i)
            }
            wg.Wait()
            fmt.Println("all done")
        - id: v2
          title: Concurrent Sleepers
          description: >-
            Launch 3 goroutines that each sleep for a different duration (100ms, 200ms, 300ms) then print their
            duration. All should run concurrently — total time should be ~300ms, not 600ms. Use WaitGroup.
          expected: |-
            100ms done
            200ms done
            300ms done
            total: ~300ms
            (line order may vary; exact total varies)
          hints:
            - Use <code>time.Sleep(time.Duration(ms) * time.Millisecond)</code>
            - If total time is ~300ms, they ran concurrently. If ~600ms, they ran sequentially.
          solution: |-
            var wg sync.WaitGroup
            durations := []int{100, 200, 300}
            start := time.Now()
            for _, ms := range durations {
                wg.Add(1)
                go func(d int) {
                    defer wg.Done()
                    time.Sleep(time.Duration(d) * time.Millisecond)
                    fmt.Printf("%dms done\n", d)
                }(ms)
            }
            wg.Wait()
            fmt.Printf("total: %v\n", time.Since(start)) // ~300ms
    - id: warmup_2
      concept: Channels
      variants:
        - id: v1
          title: Send and Receive
          description: >-
            Create a channel of strings. Launch a goroutine that sends <code>"ping"</code>. Receive and print the value
            in main.
          hints:
            - <code>ch := make(chan string)</code>
            - "Send: <code>ch <- \"ping\"</code>, Receive: <code>msg := <-ch</code>"
          solution: |-
            ch := make(chan string)
            go func() {
                ch <- "ping"
            }()
            msg := <-ch
            fmt.Println(msg) // ping
        - id: v2
          title: Buffered Channel Pipeline
          description: >-
            Create a buffered channel of int with capacity 5. Send values 1-5 without any goroutines (all in main). Then
            read and print all 5 values.
          hints:
            - "Buffered channel: <code>make(chan int, 5)</code>"
            - Sends won't block because buffer has room
          solution: |-
            ch := make(chan int, 5)
            for i := 1; i <= 5; i++ {
                ch <- i
            }
            close(ch)
            for val := range ch {
                fmt.Println(val)
            }
        - id: v3
          title: Generator Pattern
          description: >-
            Write a function <code>generate(nums ...int) <-chan int</code> that launches a goroutine to send all numbers
            on a channel, closes it, and returns the receive-only channel. Read all values with range.
          hints:
            - Return type <code><-chan int</code> is a receive-only channel
            - Close the channel after sending all values so range terminates
          solution: |-
            func generate(nums ...int) <-chan int {
                ch := make(chan int)
                go func() {
                    for _, n := range nums {
                        ch <- n
                    }
                    close(ch)
                }()
                return ch
            }

            for val := range generate(10, 20, 30) {
                fmt.Println(val)
            }
    - id: warmup_3
      concept: WaitGroups
      variants:
        - id: v1
          title: Parallel URL Fetch
          description: >-
            Given a slice of 5 URLs (strings), launch a goroutine for each that simulates a fetch (just prints the URL).
            Use WaitGroup to wait for all. Print <code>"all fetched"</code> when done.
          hints:
            - "Pattern: wg.Add(1) → go func(url) { defer wg.Done(); ... }(url) → wg.Wait()"
          solution: |-
            urls := []string{"https://a.com", "https://b.com", "https://c.com", "https://d.com", "https://e.com"}
            var wg sync.WaitGroup
            for _, url := range urls {
                wg.Add(1)
                go func(u string) {
                    defer wg.Done()
                    fmt.Printf("fetched %s\n", u)
                }(url)
            }
            wg.Wait()
            fmt.Println("all fetched")
        - id: v2
          title: Collect Results with Channel + WaitGroup
          description: >-
            Launch 5 goroutines that each compute a result (e.g., <code>i * i</code>). Send results to a buffered
            channel. Use a WaitGroup to know when to close the channel. Collect results with range in main.
          hints:
            - Launch a separate goroutine that does <code>wg.Wait(); close(ch)</code>
            - The main goroutine reads with <code>for val := range ch</code>
          solution: |-
            ch := make(chan int, 5)
            var wg sync.WaitGroup
            for i := 1; i <= 5; i++ {
                wg.Add(1)
                go func(n int) {
                    defer wg.Done()
                    ch <- n * n
                }(i)
            }
            go func() {
                wg.Wait()
                close(ch)
            }()
            for val := range ch {
                fmt.Println(val)
            }
  challenges:
    - id: challenge_1
      block: 1
      difficulty: 2
      concept: Concurrent Patterns
      variants:
        - id: v1
          title: Parallel Health Check
          description: >-
            Write <code>checkHealth(endpoints []string) []Result</code>. Each Result has URL, Healthy (bool), and
            Latency (time.Duration). Check all endpoints concurrently using goroutines and a buffered channel. Simulate
            the check with <code>time.Sleep(50ms)</code> and random health.
          functionSignature: func checkHealth(endpoints []string) []Result
          difficulty: 1
          testCases:
            - input: checkHealth([]string{"svc-a", "svc-b", "svc-c"})
              output: "[]Result with 3 entries, total time ~50ms not 150ms"
          hints:
            - title: Think about it
              content: >-
                Launch one goroutine per endpoint. Each sends a Result to a buffered channel. Main collects
                len(endpoints) results.
            - title: Hint
              content: >-
                Buffered channel: <code>make(chan Result, len(endpoints))</code>. Each goroutine records start time,
                does the check, sends Result. Main reads exactly <code>len(endpoints)</code> times.
          solution: |-
            type Result struct {
                URL     string
                Healthy bool
                Latency time.Duration
            }

            func checkHealth(endpoints []string) []Result {
                results := make(chan Result, len(endpoints))
                for _, ep := range endpoints {
                    go func(url string) {
                        start := time.Now()
                        time.Sleep(50 * time.Millisecond) // simulate check
                        results <- Result{
                            URL:     url,
                            Healthy: true,
                            Latency: time.Since(start),
                        }
                    }(ep)
                }
                all := make([]Result, 0, len(endpoints))
                for i := 0; i < len(endpoints); i++ {
                    all = append(all, <-results)
                }
                return all
            }
          annotations:
            - type: pattern
              label: Fan-out collect
              text: Launch N goroutines, collect N results from a channel. The simplest concurrent pattern in Go.
            - type: complexity
              label: O(max latency)
              text: Total time is the slowest endpoint, not the sum. That's the power of concurrency.
        - id: v2
          title: Concurrent File Processor
          description: >-
            Write <code>processFiles(paths []string, fn func(string) (int, error)) (map[string]int, error)</code>.
            Process all files concurrently. Each goroutine calls fn(path) which returns a line count. Collect results
            into a map[path]count. If any goroutine returns an error, return the first error.
          functionSignature: func processFiles(paths []string, fn func(string) (int, error)) (map[string]int, error)
          difficulty: 2
          testCases:
            - input: processFiles([]string{"a.log", "b.log"}, countLines)
              output: (map[a.log:100 b.log:200], nil)
            - input: processFiles([]string{"a.log", "missing.log"}, countLines)
              output: (nil, error)
          hints:
            - title: Think about it
              content: Each goroutine sends either a result or an error on a channel. Collect all, check for errors.
            - title: Hint
              content: >-
                Define a result struct: <code>{Path string; Count int; Err error}</code>. Send one per goroutine. After
                collecting all, check for errors.
          solution: |-
            type fileResult struct {
                Path  string
                Count int
                Err   error
            }

            func processFiles(paths []string, fn func(string) (int, error)) (map[string]int, error) {
                results := make(chan fileResult, len(paths))
                for _, p := range paths {
                    go func(path string) {
                        count, err := fn(path)
                        results <- fileResult{Path: path, Count: count, Err: err}
                    }(p)
                }

                counts := make(map[string]int)
                for i := 0; i < len(paths); i++ {
                    r := <-results
                    if r.Err != nil {
                        return nil, fmt.Errorf("processing %s: %w", r.Path, r.Err)
                    }
                    counts[r.Path] = r.Count
                }
                return counts, nil
            }
          annotations:
            - type: pattern
              label: Result struct
              text: When goroutines can fail, include Err in the result struct. Check errors after collecting all results.
            - type: gotcha
              label: First error wins
              text: >-
                We return on first error. Alternative: collect all errors and return them all. Both are valid depending
                on use case.
        - id: v3
          title: "Pipeline: Generate → Filter → Collect"
          description: >-
            Build a three-stage pipeline using channels. Stage 1: <code>generate()</code> sends integers 1-100 on a
            channel. Stage 2: <code>filter(in <-chan int)</code> reads from generate's channel, keeps only multiples of
            7, sends to output channel. Stage 3: main collects and prints results. Each stage runs in its own goroutine.
          functionSignature: func generate() <-chan int; func filter(in <-chan int) <-chan int
          difficulty: 3
          testCases:
            - input: // pipeline output
              output: "[7, 14, 21, 28, 35, 42, 49, 56, 63, 70, 77, 84, 91, 98]"
          hints:
            - title: Think about it
              content: >-
                Each stage is a function that returns a channel. The next stage takes that channel as input. Goroutines
                connect the pipeline.
            - title: Hint
              content: >-
                generate: create channel, goroutine sends 1-100, closes. filter: create output channel, goroutine ranges
                over input, sends matches, closes output. Main: range over filter's output.
          solution: |-
            func generate() <-chan int {
                ch := make(chan int)
                go func() {
                    for i := 1; i <= 100; i++ {
                        ch <- i
                    }
                    close(ch)
                }()
                return ch
            }

            func filter(in <-chan int) <-chan int {
                out := make(chan int)
                go func() {
                    for n := range in {
                        if n%7 == 0 {
                            out <- n
                        }
                    }
                    close(out)
                }()
                return out
            }

            // Usage:
            for val := range filter(generate()) {
                fmt.Println(val)
            }
          annotations:
            - type: pattern
              label: Channel pipeline
              text: >-
                Each stage: create output channel, launch goroutine, close when done. Chain stages by passing channels.
                This is the Unix pipe model in Go.
            - type: interview
              label: Pipeline pattern
              text: >-
                This is a classic Go interview question. Know how to build multi-stage pipelines with channels and how
                to handle cancellation.
            - type: idiom
              label: Return <-chan T
              text: Returning receive-only channels prevents the caller from accidentally sending on or closing the channel.
    - id: challenge_2
      block: 2
      difficulty: 2
      concept: Channels
      variants:
        - id: v1
          title: Merge Two Channels
          description: >-
            Write <code>merge(ch1, ch2 <-chan string) <-chan string</code> that reads from both input channels and sends
            all values to a single output channel. Close the output when both inputs are exhausted.
          functionSignature: func merge(ch1, ch2 <-chan string) <-chan string
          difficulty: 1
          testCases:
            - input: merge(chan with ["a","b"], chan with ["c","d"])
              output: chan with all 4 values (order may vary)
          hints:
            - title: Think about it
              content: >-
                Launch two goroutines — one reads ch1, one reads ch2. Both send to output. Use WaitGroup to close output
                when both are done.
            - title: Hint
              content: >-
                Two goroutines range over their input and send to output. A third goroutine waits on the WaitGroup and
                closes output.
          solution: |-
            func merge(ch1, ch2 <-chan string) <-chan string {
                out := make(chan string)
                var wg sync.WaitGroup
                wg.Add(2)

                drain := func(ch <-chan string) {
                    defer wg.Done()
                    for val := range ch {
                        out <- val
                    }
                }
                go drain(ch1)
                go drain(ch2)

                go func() {
                    wg.Wait()
                    close(out)
                }()
                return out
            }
          annotations:
            - type: pattern
              label: Fan-in / merge
              text: Multiple producers, one consumer. WaitGroup + closer goroutine is the standard pattern.
            - type: idiom
              label: Drain helper
              text: Extract the 'read from channel, send to output' logic into a helper to avoid duplication.
        - id: v2
          title: Timeout Pattern
          description: >-
            Write <code>fetchWithTimeout(fn func() string, timeout time.Duration) (string, error)</code>. Launch fn in a
            goroutine. If it returns before the timeout, return the result. If the timeout fires first, return an error.
            Use <code>select</code>.
          functionSignature: func fetchWithTimeout(fn func() string, timeout time.Duration) (string, error)
          difficulty: 2
          testCases:
            - input: fetchWithTimeout(func() string { return "ok" }, 1*time.Second)
              output: ("ok", nil)
            - input: fetchWithTimeout(func() string { time.Sleep(2*time.Second); return "late" }, 100*time.Millisecond)
              output: ("", timeout error)
          hints:
            - title: Think about it
              content: >-
                Launch fn in a goroutine that sends to a channel. In main, select between the result channel and
                time.After.
            - title: Hint
              content: >-
                <code>select { case result := <-ch: return result, nil; case <-time.After(timeout): return "",
                fmt.Errorf("timeout") }</code>
          solution: |-
            func fetchWithTimeout(fn func() string, timeout time.Duration) (string, error) {
                ch := make(chan string, 1) // buffered so goroutine doesn't leak on timeout
                go func() {
                    ch <- fn()
                }()
                select {
                case result := <-ch:
                    return result, nil
                case <-time.After(timeout):
                    return "", fmt.Errorf("operation timed out after %v", timeout)
                }
            }
          annotations:
            - type: pattern
              label: Select timeout
              text: select + time.After is the standard Go timeout pattern. The first case that's ready wins.
            - type: gotcha
              label: Buffered channel for timeout
              text: >-
                Use buffer of 1 so the goroutine can send even after timeout. Without buffer, the goroutine leaks
                because nobody reads from ch.
            - type: interview
              label: Classic question
              text: "\"Implement a function with timeout\" is asked in nearly every Go interview. Know this pattern cold."
        - id: v3
          title: Bounded Concurrent Workers
          description: >-
            Write <code>processAll(items []string, maxConcurrent int, fn func(string) string) []string</code>. Process
            all items using at most <code>maxConcurrent</code> goroutines at a time. Use a semaphore (buffered channel)
            to limit concurrency. Return results in input order.
          functionSignature: func processAll(items []string, maxConcurrent int, fn func(string) string) []string
          difficulty: 3
          testCases:
            - input: processAll([]string{"a","b","c","d","e"}, 2, strings.ToUpper)
              output: "[\"A\",\"B\",\"C\",\"D\",\"E\"]"
          hints:
            - title: Think about it
              content: >-
                Results must be in input order, but processing is concurrent. Use an indexed results slice and a
                semaphore channel.
            - title: Hint
              content: >-
                Pre-allocate <code>results := make([]string, len(items))</code>. Semaphore: <code>sem := make(chan
                struct{}, maxConcurrent)</code>. Each goroutine acquires (<code>sem <- struct{}{}</code>), processes,
                writes to <code>results[i]</code>, releases (<code><-sem</code>).
          solution: |-
            func processAll(items []string, maxConcurrent int, fn func(string) string) []string {
                results := make([]string, len(items))
                sem := make(chan struct{}, maxConcurrent)
                var wg sync.WaitGroup

                for i, item := range items {
                    wg.Add(1)
                    sem <- struct{}{} // acquire (blocks if maxConcurrent reached)
                    go func(idx int, val string) {
                        defer wg.Done()
                        defer func() { <-sem }() // release
                        results[idx] = fn(val)
                    }(i, item)
                }
                wg.Wait()
                return results
            }
          annotations:
            - type: pattern
              label: Semaphore
              text: "Buffered channel as semaphore: send to acquire, receive to release. Controls max concurrent goroutines."
            - type: idiom
              label: Indexed results
              text: >-
                Pre-allocate results slice, write by index. Each goroutine writes to its own index — no race condition,
                results stay ordered.
            - type: interview
              label: Bounded concurrency
              text: >-
                "Process N items with at most K concurrent workers" is a top-5 Go interview question. This is the
                cleanest solution.
