conceptLinks:
  Rolling Updates: "#rolling-updates-deep-dive"
  Controlling Rollout Speed: "#controlling-rollout-speed"
  minReadySeconds: "#minreadyseconds"
  progressDeadlineSeconds: "#progressdeadlineseconds"
  Recreate Strategy: "#recreate-strategy"
  Blue-Green Deployments: "#blue-green-deployments"
  Canary Deployments: "#canary-deployments"
  Gateway API Canary: "#gateway-api-canary-weight-based"
  A/B Testing: "#ab-testing"
  Argo Rollouts: "#argo-rollouts"
  Pod Disruption Budgets: "#pod-disruption-budgets-pdb"
  Strategy Comparison: "#strategy-comparison"
sharedContent: {}
variants:
  warmups:
    - id: warmup_1
      concept: "Rolling Updates"
      variants:
        - id: v1
          title: "Safe Rolling Update (maxSurge=1, maxUnavailable=0)"
          description: >-
            Write a Deployment named <code>api-server</code> with <code>4</code> replicas using image
            <code>api:2.0</code>. Configure a RollingUpdate strategy with <code>maxSurge: 1</code> and
            <code>maxUnavailable: 0</code> for the safest possible rollout.
          hints:
            - "The strategy section goes under <code>spec.strategy</code> with <code>type: RollingUpdate</code>."
            - "<code>maxSurge: 1</code> means at most 5 Pods total during the update (4 desired + 1 extra)."
            - "<code>maxUnavailable: 0</code> means all 4 replicas must stay running at all times."
          solution: |-
            apiVersion: apps/v1
            kind: Deployment
            metadata:
              name: api-server
            spec:
              replicas: 4
              strategy:
                type: RollingUpdate
                rollingUpdate:
                  maxSurge: 1
                  maxUnavailable: 0
              selector:
                matchLabels:
                  app: api-server
              template:
                metadata:
                  labels:
                    app: api-server
                spec:
                  containers:
                  - name: api
                    image: api:2.0
                    ports:
                    - containerPort: 8080
        - id: v2
          title: "Resource-Constrained Rolling Update (maxSurge=0, maxUnavailable=1)"
          description: >-
            Write a Deployment named <code>worker</code> with <code>6</code> replicas using image
            <code>worker:3.1</code>. Configure a RollingUpdate that uses no extra resources: <code>maxSurge: 0</code>
            and <code>maxUnavailable: 1</code>. This kills one old Pod before creating a new one.
          hints:
            - "With <code>maxSurge: 0</code>, no extra Pods are created above the desired count."
            - "With <code>maxUnavailable: 1</code>, one Pod is terminated first, making room for a new one."
            - "This approach is slower but uses no additional cluster resources during the rollout."
          solution: |-
            apiVersion: apps/v1
            kind: Deployment
            metadata:
              name: worker
            spec:
              replicas: 6
              strategy:
                type: RollingUpdate
                rollingUpdate:
                  maxSurge: 0
                  maxUnavailable: 1
              selector:
                matchLabels:
                  app: worker
              template:
                metadata:
                  labels:
                    app: worker
                spec:
                  containers:
                  - name: worker
                    image: worker:3.1
                    ports:
                    - containerPort: 9090
        - id: v3
          title: "Default Rolling Update (25%/25%)"
          description: >-
            Write a Deployment named <code>frontend</code> with <code>8</code> replicas using image
            <code>frontend:1.5</code>. Use the Kubernetes default rolling update settings:
            <code>maxSurge: 25%</code> and <code>maxUnavailable: 25%</code>.
          hints:
            - "Percentage values are strings in YAML: <code>maxSurge: \"25%\"</code>."
            - "With 8 replicas and 25%, maxSurge allows 2 extra Pods (ceil of 8 * 0.25) and maxUnavailable allows 2 down."
            - "This is the Kubernetes default if you don't specify a strategy, but it's good practice to be explicit."
          solution: |-
            apiVersion: apps/v1
            kind: Deployment
            metadata:
              name: frontend
            spec:
              replicas: 8
              strategy:
                type: RollingUpdate
                rollingUpdate:
                  maxSurge: "25%"
                  maxUnavailable: "25%"
              selector:
                matchLabels:
                  app: frontend
              template:
                metadata:
                  labels:
                    app: frontend
                spec:
                  containers:
                  - name: frontend
                    image: frontend:1.5
                    ports:
                    - containerPort: 3000
        - id: v4
          title: "Fast Rolling Update (maxSurge=100%, maxUnavailable=0)"
          description: >-
            Write a Deployment named <code>web-app</code> with <code>3</code> replicas using image
            <code>webapp:4.0</code>. Configure a blue-green-like rolling update: <code>maxSurge: "100%"</code> and
            <code>maxUnavailable: 0</code>. This creates all new Pods first, then kills old ones.
          hints:
            - "<code>maxSurge: \"100%\"</code> means Kubernetes can create up to 3 extra Pods (doubling the count)."
            - "All new Pods come up before any old Pods are terminated."
            - "This behaves like blue-green within a single Deployment but doubles resources temporarily."
          solution: |-
            apiVersion: apps/v1
            kind: Deployment
            metadata:
              name: web-app
            spec:
              replicas: 3
              strategy:
                type: RollingUpdate
                rollingUpdate:
                  maxSurge: "100%"
                  maxUnavailable: 0
              selector:
                matchLabels:
                  app: web-app
              template:
                metadata:
                  labels:
                    app: web-app
                spec:
                  containers:
                  - name: app
                    image: webapp:4.0
                    ports:
                    - containerPort: 8080
        - id: v5
          title: "Rolling Update with minReadySeconds"
          description: >-
            Write a Deployment named <code>payment-svc</code> with <code>5</code> replicas using image
            <code>payment:2.3</code>. Use <code>maxSurge: 1</code>, <code>maxUnavailable: 0</code>, and set
            <code>minReadySeconds: 30</code> so each new Pod must be Ready for 30 seconds before the rollout
            continues.
          hints:
            - "<code>minReadySeconds</code> goes under <code>spec</code>, at the same level as <code>strategy</code>."
            - "This catches Pods that pass the initial health check but crash shortly after."
            - "A value of 30 gives the Pod time to warm up caches and establish connections."
          solution: |-
            apiVersion: apps/v1
            kind: Deployment
            metadata:
              name: payment-svc
            spec:
              replicas: 5
              minReadySeconds: 30
              strategy:
                type: RollingUpdate
                rollingUpdate:
                  maxSurge: 1
                  maxUnavailable: 0
              selector:
                matchLabels:
                  app: payment-svc
              template:
                metadata:
                  labels:
                    app: payment-svc
                spec:
                  containers:
                  - name: payment
                    image: payment:2.3
                    ports:
                    - containerPort: 8080
        - id: v6
          title: "Rolling Update with progressDeadlineSeconds"
          description: >-
            Write a Deployment named <code>order-svc</code> with <code>4</code> replicas using image
            <code>orders:1.8</code>. Set <code>progressDeadlineSeconds: 300</code> (5 minutes),
            <code>minReadySeconds: 10</code>, <code>maxSurge: 1</code>, and <code>maxUnavailable: 0</code>.
          hints:
            - "<code>progressDeadlineSeconds</code> goes under <code>spec</code> alongside <code>minReadySeconds</code>."
            - "The default is 600 seconds. Setting it to 300 catches stuck rollouts faster."
            - "The timer resets each time a new Pod becomes Ready."
          solution: |-
            apiVersion: apps/v1
            kind: Deployment
            metadata:
              name: order-svc
            spec:
              replicas: 4
              minReadySeconds: 10
              progressDeadlineSeconds: 300
              strategy:
                type: RollingUpdate
                rollingUpdate:
                  maxSurge: 1
                  maxUnavailable: 0
              selector:
                matchLabels:
                  app: order-svc
              template:
                metadata:
                  labels:
                    app: order-svc
                spec:
                  containers:
                  - name: orders
                    image: orders:1.8
                    ports:
                    - containerPort: 8080
        - id: v7
          title: "Aggressive Rolling Update (maxSurge=2, maxUnavailable=2)"
          description: >-
            Write a Deployment named <code>batch-processor</code> with <code>10</code> replicas using image
            <code>batch:5.0</code>. Configure an aggressive rolling update with <code>maxSurge: 2</code> and
            <code>maxUnavailable: 2</code> for faster rollout at the cost of temporary reduced capacity.
          hints:
            - "With maxSurge=2, up to 12 Pods can exist during the rollout."
            - "With maxUnavailable=2, as few as 8 Pods may be available during the update."
            - "This is useful for non-critical batch workloads where speed matters more than full capacity."
          solution: |-
            apiVersion: apps/v1
            kind: Deployment
            metadata:
              name: batch-processor
            spec:
              replicas: 10
              strategy:
                type: RollingUpdate
                rollingUpdate:
                  maxSurge: 2
                  maxUnavailable: 2
              selector:
                matchLabels:
                  app: batch-processor
              template:
                metadata:
                  labels:
                    app: batch-processor
                spec:
                  containers:
                  - name: batch
                    image: batch:5.0
                    ports:
                    - containerPort: 8080
        - id: v8
          title: "Rolling Update with Percentage maxUnavailable"
          description: >-
            Write a Deployment named <code>notifications</code> with <code>12</code> replicas using image
            <code>notify:2.0</code>. Use <code>maxSurge: "10%"</code> and <code>maxUnavailable: "10%"</code>
            for a gradual rollout in a large replica set.
          hints:
            - "With 12 replicas and 10%, maxSurge rounds up to 2 extra Pods."
            - "maxUnavailable rounds down to 1 (floor of 12 * 0.10 = 1.2, but Kubernetes rounds up for maxUnavailable too, so it is 2)."
            - "Percentages scale naturally as you change the replica count."
          solution: |-
            apiVersion: apps/v1
            kind: Deployment
            metadata:
              name: notifications
            spec:
              replicas: 12
              strategy:
                type: RollingUpdate
                rollingUpdate:
                  maxSurge: "10%"
                  maxUnavailable: "10%"
              selector:
                matchLabels:
                  app: notifications
              template:
                metadata:
                  labels:
                    app: notifications
                spec:
                  containers:
                  - name: notify
                    image: notify:2.0
                    ports:
                    - containerPort: 8080
        - id: v9
          title: "Rolling Update with Readiness Probe"
          description: >-
            Write a Deployment named <code>auth-svc</code> with <code>3</code> replicas using image
            <code>auth:3.0</code>. Configure <code>maxSurge: 1</code>, <code>maxUnavailable: 0</code>,
            <code>minReadySeconds: 15</code>, and include an HTTP readiness probe on <code>/healthz</code>
            port <code>8080</code> with <code>initialDelaySeconds: 5</code> and <code>periodSeconds: 5</code>.
          hints:
            - "The readiness probe ensures Pods only receive traffic when healthy."
            - "Combined with <code>maxUnavailable: 0</code>, the rollout waits for each new Pod to pass its probe."
            - "<code>minReadySeconds: 15</code> adds an additional 15-second buffer after the probe passes."
          solution: |-
            apiVersion: apps/v1
            kind: Deployment
            metadata:
              name: auth-svc
            spec:
              replicas: 3
              minReadySeconds: 15
              strategy:
                type: RollingUpdate
                rollingUpdate:
                  maxSurge: 1
                  maxUnavailable: 0
              selector:
                matchLabels:
                  app: auth-svc
              template:
                metadata:
                  labels:
                    app: auth-svc
                spec:
                  containers:
                  - name: auth
                    image: auth:3.0
                    ports:
                    - containerPort: 8080
                    readinessProbe:
                      httpGet:
                        path: /healthz
                        port: 8080
                      initialDelaySeconds: 5
                      periodSeconds: 5
        - id: v10
          title: "Recreate Strategy"
          description: >-
            Write a Deployment named <code>legacy-db-migrator</code> with <code>1</code> replica using image
            <code>migrator:1.2</code>. Use the <code>Recreate</code> strategy because only one instance can run
            at a time (it holds a lock on the database schema).
          hints:
            - "Set <code>strategy.type: Recreate</code> with no <code>rollingUpdate</code> section."
            - "Recreate kills all old Pods before creating new ones, causing downtime."
            - "Use this when two versions cannot coexist (e.g., schema migrations, RWO volumes)."
          solution: |-
            apiVersion: apps/v1
            kind: Deployment
            metadata:
              name: legacy-db-migrator
            spec:
              replicas: 1
              strategy:
                type: Recreate
              selector:
                matchLabels:
                  app: legacy-db-migrator
              template:
                metadata:
                  labels:
                    app: legacy-db-migrator
                spec:
                  containers:
                  - name: migrator
                    image: migrator:1.2
                    ports:
                    - containerPort: 5000
        - id: v11
          title: "Rolling Update with All Safety Controls"
          description: >-
            Write a Deployment named <code>checkout-svc</code> with <code>6</code> replicas using image
            <code>checkout:4.1</code>. Configure the safest possible rollout: <code>maxSurge: 1</code>,
            <code>maxUnavailable: 0</code>, <code>minReadySeconds: 45</code>,
            <code>progressDeadlineSeconds: 900</code>, and an HTTP readiness probe on <code>/ready</code>
            port <code>8080</code>.
          hints:
            - "<code>minReadySeconds: 45</code> gives the Pod nearly a minute to prove it is stable."
            - "<code>progressDeadlineSeconds: 900</code> gives 15 minutes before declaring the rollout stuck."
            - "Combined with <code>maxUnavailable: 0</code>, this never drops below 6 available Pods."
          solution: |-
            apiVersion: apps/v1
            kind: Deployment
            metadata:
              name: checkout-svc
            spec:
              replicas: 6
              minReadySeconds: 45
              progressDeadlineSeconds: 900
              strategy:
                type: RollingUpdate
                rollingUpdate:
                  maxSurge: 1
                  maxUnavailable: 0
              selector:
                matchLabels:
                  app: checkout-svc
              template:
                metadata:
                  labels:
                    app: checkout-svc
                spec:
                  containers:
                  - name: checkout
                    image: checkout:4.1
                    ports:
                    - containerPort: 8080
                    readinessProbe:
                      httpGet:
                        path: /ready
                        port: 8080
                      initialDelaySeconds: 10
                      periodSeconds: 5
        - id: v12
          title: "Mixed Percentage and Absolute Rolling Update"
          description: >-
            Write a Deployment named <code>search-svc</code> with <code>20</code> replicas using image
            <code>search:3.0</code>. Configure <code>maxSurge: "50%"</code> and <code>maxUnavailable: 0</code>
            for a fast rollout that never reduces availability.
          hints:
            - "With 20 replicas and 50% maxSurge, up to 30 Pods can exist during the rollout."
            - "<code>maxUnavailable: 0</code> ensures all 20 original replicas stay running until replacements are Ready."
            - "This is an aggressive but safe approach when you have spare cluster capacity."
          solution: |-
            apiVersion: apps/v1
            kind: Deployment
            metadata:
              name: search-svc
            spec:
              replicas: 20
              strategy:
                type: RollingUpdate
                rollingUpdate:
                  maxSurge: "50%"
                  maxUnavailable: 0
              selector:
                matchLabels:
                  app: search-svc
              template:
                metadata:
                  labels:
                    app: search-svc
                spec:
                  containers:
                  - name: search
                    image: search:3.0
                    ports:
                    - containerPort: 8080
    - id: warmup_2
      concept: "Blue-Green Deployments"
      variants:
        - id: v1
          title: "Basic Blue-Green: Blue Deployment + Service"
          description: >-
            Write a blue Deployment named <code>app-blue</code> with <code>3</code> replicas using image
            <code>myapp:1.0</code> and labels <code>app: web</code>, <code>version: blue</code>. Then write
            a Service named <code>web</code> that selects <code>version: blue</code>.
          hints:
            - "Both the Deployment selector and Pod template labels need <code>app: web</code> and <code>version: blue</code>."
            - "The Service selector must match the Pod labels: <code>app: web</code> and <code>version: blue</code>."
            - "Use <code>---</code> to separate multiple YAML documents."
          solution: |-
            apiVersion: apps/v1
            kind: Deployment
            metadata:
              name: app-blue
            spec:
              replicas: 3
              selector:
                matchLabels:
                  app: web
                  version: blue
              template:
                metadata:
                  labels:
                    app: web
                    version: blue
                spec:
                  containers:
                  - name: app
                    image: myapp:1.0
                    ports:
                    - containerPort: 8080
            ---
            apiVersion: v1
            kind: Service
            metadata:
              name: web
            spec:
              selector:
                app: web
                version: blue
              ports:
              - port: 80
                targetPort: 8080
        - id: v2
          title: "Blue-Green: Green Deployment"
          description: >-
            Given an existing blue Deployment with labels <code>app: web</code>, <code>version: blue</code>,
            write the green Deployment named <code>app-green</code> with <code>3</code> replicas using image
            <code>myapp:2.0</code> and labels <code>app: web</code>, <code>version: green</code>. The green
            Deployment does not receive traffic yet.
          hints:
            - "The green Deployment has the same <code>app: web</code> label so it matches the app grouping."
            - "The <code>version: green</code> label differentiates it from blue."
            - "The Service still points to <code>version: blue</code> so green gets no traffic until you switch."
          solution: |-
            apiVersion: apps/v1
            kind: Deployment
            metadata:
              name: app-green
            spec:
              replicas: 3
              selector:
                matchLabels:
                  app: web
                  version: green
              template:
                metadata:
                  labels:
                    app: web
                    version: green
                spec:
                  containers:
                  - name: app
                    image: myapp:2.0
                    ports:
                    - containerPort: 8080
        - id: v3
          title: "Blue-Green: Switch Service to Green"
          description: >-
            Write the <code>kubectl patch</code> command to switch the Service named <code>web</code> from
            blue to green. Then write the patched Service YAML showing the selector pointing to
            <code>version: green</code>.
          hints:
            - "Use <code>kubectl patch svc web -p '{\"spec\":{\"selector\":{\"version\":\"green\"}}}'</code>."
            - "The patched Service only changes the <code>version</code> value in the selector."
            - "The <code>app: web</code> selector stays the same."
          solution: |-
            # Command to switch:
            # kubectl patch svc web -p '{"spec":{"selector":{"version":"green"}}}'

            apiVersion: v1
            kind: Service
            metadata:
              name: web
            spec:
              selector:
                app: web
                version: green
              ports:
              - port: 80
                targetPort: 8080
        - id: v4
          title: "Blue-Green: Full Setup with Both Deployments"
          description: >-
            Write the complete blue-green setup for an app called <code>payments</code>: a blue Deployment
            (<code>payments-blue</code>, <code>3</code> replicas, image <code>payments:1.0</code>), a green
            Deployment (<code>payments-green</code>, <code>3</code> replicas, image <code>payments:2.0</code>),
            and a Service (<code>payments</code>) pointing to blue.
          hints:
            - "Both Deployments share the <code>app: payments</code> label."
            - "Blue has <code>version: blue</code>, green has <code>version: green</code>."
            - "The Service selects <code>app: payments, version: blue</code> initially."
          solution: |-
            apiVersion: apps/v1
            kind: Deployment
            metadata:
              name: payments-blue
            spec:
              replicas: 3
              selector:
                matchLabels:
                  app: payments
                  version: blue
              template:
                metadata:
                  labels:
                    app: payments
                    version: blue
                spec:
                  containers:
                  - name: payments
                    image: payments:1.0
                    ports:
                    - containerPort: 8080
            ---
            apiVersion: apps/v1
            kind: Deployment
            metadata:
              name: payments-green
            spec:
              replicas: 3
              selector:
                matchLabels:
                  app: payments
                  version: green
              template:
                metadata:
                  labels:
                    app: payments
                    version: green
                spec:
                  containers:
                  - name: payments
                    image: payments:2.0
                    ports:
                    - containerPort: 8080
            ---
            apiVersion: v1
            kind: Service
            metadata:
              name: payments
            spec:
              selector:
                app: payments
                version: blue
              ports:
              - port: 80
                targetPort: 8080
        - id: v5
          title: "Blue-Green: Rollback to Blue"
          description: >-
            You deployed green and switched the Service, but errors spiked. Write the <code>kubectl patch</code>
            command to instantly roll back the Service named <code>payments</code> to blue. Then write the
            rollback Service YAML.
          hints:
            - "Rollback is just switching the selector back: <code>version: blue</code>."
            - "This is the main advantage of blue-green: instant rollback by patching one field."
            - "The blue Deployment is still running with the old version, ready to serve immediately."
          solution: |-
            # Instant rollback command:
            # kubectl patch svc payments -p '{"spec":{"selector":{"version":"blue"}}}'

            apiVersion: v1
            kind: Service
            metadata:
              name: payments
            spec:
              selector:
                app: payments
                version: blue
              ports:
              - port: 80
                targetPort: 8080
        - id: v6
          title: "Blue-Green: Different Port Configuration"
          description: >-
            Write a blue-green setup for a gRPC service: blue Deployment <code>grpc-blue</code> (2 replicas,
            image <code>grpc-svc:1.0</code>, container port <code>50051</code>), green Deployment
            <code>grpc-green</code> (2 replicas, image <code>grpc-svc:2.0</code>), and Service
            <code>grpc-svc</code> on port <code>50051</code> pointing to blue.
          hints:
            - "gRPC typically uses port 50051."
            - "The Service port and targetPort can both be 50051 for simplicity."
            - "Same blue-green pattern, just different ports and app name."
          solution: |-
            apiVersion: apps/v1
            kind: Deployment
            metadata:
              name: grpc-blue
            spec:
              replicas: 2
              selector:
                matchLabels:
                  app: grpc-svc
                  version: blue
              template:
                metadata:
                  labels:
                    app: grpc-svc
                    version: blue
                spec:
                  containers:
                  - name: grpc
                    image: grpc-svc:1.0
                    ports:
                    - containerPort: 50051
            ---
            apiVersion: apps/v1
            kind: Deployment
            metadata:
              name: grpc-green
            spec:
              replicas: 2
              selector:
                matchLabels:
                  app: grpc-svc
                  version: green
              template:
                metadata:
                  labels:
                    app: grpc-svc
                    version: green
                spec:
                  containers:
                  - name: grpc
                    image: grpc-svc:2.0
                    ports:
                    - containerPort: 50051
            ---
            apiVersion: v1
            kind: Service
            metadata:
              name: grpc-svc
            spec:
              selector:
                app: grpc-svc
                version: blue
              ports:
              - port: 50051
                targetPort: 50051
        - id: v7
          title: "Blue-Green: With Resource Limits"
          description: >-
            Write a blue-green setup for <code>catalog-svc</code> where each Deployment has <code>3</code>
            replicas with resource requests of <code>128Mi</code> memory and <code>100m</code> CPU, and limits
            of <code>256Mi</code> and <code>200m</code>. Blue uses image <code>catalog:3.0</code>, green uses
            <code>catalog:4.0</code>. Service points to blue.
          hints:
            - "Resources go under <code>spec.template.spec.containers[].resources</code>."
            - "Remember: blue-green doubles your resource usage during deployment."
            - "With 3 replicas per Deployment, you need capacity for 6 Pods during the transition."
          solution: |-
            apiVersion: apps/v1
            kind: Deployment
            metadata:
              name: catalog-blue
            spec:
              replicas: 3
              selector:
                matchLabels:
                  app: catalog-svc
                  version: blue
              template:
                metadata:
                  labels:
                    app: catalog-svc
                    version: blue
                spec:
                  containers:
                  - name: catalog
                    image: catalog:3.0
                    ports:
                    - containerPort: 8080
                    resources:
                      requests:
                        memory: "128Mi"
                        cpu: "100m"
                      limits:
                        memory: "256Mi"
                        cpu: "200m"
            ---
            apiVersion: apps/v1
            kind: Deployment
            metadata:
              name: catalog-green
            spec:
              replicas: 3
              selector:
                matchLabels:
                  app: catalog-svc
                  version: green
              template:
                metadata:
                  labels:
                    app: catalog-svc
                    version: green
                spec:
                  containers:
                  - name: catalog
                    image: catalog:4.0
                    ports:
                    - containerPort: 8080
                    resources:
                      requests:
                        memory: "128Mi"
                        cpu: "100m"
                      limits:
                        memory: "256Mi"
                        cpu: "200m"
            ---
            apiVersion: v1
            kind: Service
            metadata:
              name: catalog-svc
            spec:
              selector:
                app: catalog-svc
                version: blue
              ports:
              - port: 80
                targetPort: 8080
        - id: v8
          title: "Blue-Green: Named Ports"
          description: >-
            Write a blue-green setup for <code>dashboard</code> that exposes both HTTP (port 8080) and metrics
            (port 9090). Blue uses <code>dashboard:1.0</code>, green uses <code>dashboard:2.0</code>. Each
            Deployment has <code>2</code> replicas. The Service exposes port 80 for HTTP and port 9090 for
            metrics, pointing to blue.
          hints:
            - "Use named ports: <code>name: http</code> and <code>name: metrics</code>."
            - "The Service can have multiple port entries."
            - "Named ports make it clear which port serves what purpose."
          solution: |-
            apiVersion: apps/v1
            kind: Deployment
            metadata:
              name: dashboard-blue
            spec:
              replicas: 2
              selector:
                matchLabels:
                  app: dashboard
                  version: blue
              template:
                metadata:
                  labels:
                    app: dashboard
                    version: blue
                spec:
                  containers:
                  - name: dashboard
                    image: dashboard:1.0
                    ports:
                    - name: http
                      containerPort: 8080
                    - name: metrics
                      containerPort: 9090
            ---
            apiVersion: apps/v1
            kind: Deployment
            metadata:
              name: dashboard-green
            spec:
              replicas: 2
              selector:
                matchLabels:
                  app: dashboard
                  version: green
              template:
                metadata:
                  labels:
                    app: dashboard
                    version: green
                spec:
                  containers:
                  - name: dashboard
                    image: dashboard:2.0
                    ports:
                    - name: http
                      containerPort: 8080
                    - name: metrics
                      containerPort: 9090
            ---
            apiVersion: v1
            kind: Service
            metadata:
              name: dashboard
            spec:
              selector:
                app: dashboard
                version: blue
              ports:
              - name: http
                port: 80
                targetPort: 8080
              - name: metrics
                port: 9090
                targetPort: 9090
        - id: v9
          title: "Blue-Green: ClusterIP vs LoadBalancer"
          description: >-
            Write a blue-green Service for <code>api-gateway</code> of type <code>LoadBalancer</code> that
            initially points to blue. Blue uses <code>gateway:1.0</code> and green uses <code>gateway:2.0</code>,
            each with <code>3</code> replicas. Expose port 443 targeting container port 8443.
          hints:
            - "Add <code>type: LoadBalancer</code> to the Service spec."
            - "LoadBalancer gives you an external IP; the blue-green switch is still just a selector patch."
            - "The external IP stays the same when you switch from blue to green."
          solution: |-
            apiVersion: apps/v1
            kind: Deployment
            metadata:
              name: gateway-blue
            spec:
              replicas: 3
              selector:
                matchLabels:
                  app: api-gateway
                  version: blue
              template:
                metadata:
                  labels:
                    app: api-gateway
                    version: blue
                spec:
                  containers:
                  - name: gateway
                    image: gateway:1.0
                    ports:
                    - containerPort: 8443
            ---
            apiVersion: apps/v1
            kind: Deployment
            metadata:
              name: gateway-green
            spec:
              replicas: 3
              selector:
                matchLabels:
                  app: api-gateway
                  version: green
              template:
                metadata:
                  labels:
                    app: api-gateway
                    version: green
                spec:
                  containers:
                  - name: gateway
                    image: gateway:2.0
                    ports:
                    - containerPort: 8443
            ---
            apiVersion: v1
            kind: Service
            metadata:
              name: api-gateway
            spec:
              type: LoadBalancer
              selector:
                app: api-gateway
                version: blue
              ports:
              - port: 443
                targetPort: 8443
        - id: v10
          title: "Blue-Green: Minimal Single-Replica Setup"
          description: >-
            Write a minimal blue-green setup for a cron-triggered <code>report-generator</code>. Blue
            (<code>report-blue</code>, 1 replica, <code>report:1.0</code>) and green (<code>report-green</code>,
            1 replica, <code>report:2.0</code>) with a ClusterIP Service on port 80 targeting 8080.
          hints:
            - "Even with 1 replica, blue-green provides instant rollback via the Service selector."
            - "Both single-replica Deployments run simultaneously during the transition."
            - "After switching, you can delete the old Deployment to free resources."
          solution: |-
            apiVersion: apps/v1
            kind: Deployment
            metadata:
              name: report-blue
            spec:
              replicas: 1
              selector:
                matchLabels:
                  app: report-generator
                  version: blue
              template:
                metadata:
                  labels:
                    app: report-generator
                    version: blue
                spec:
                  containers:
                  - name: report
                    image: report:1.0
                    ports:
                    - containerPort: 8080
            ---
            apiVersion: apps/v1
            kind: Deployment
            metadata:
              name: report-green
            spec:
              replicas: 1
              selector:
                matchLabels:
                  app: report-generator
                  version: green
              template:
                metadata:
                  labels:
                    app: report-generator
                    version: green
                spec:
                  containers:
                  - name: report
                    image: report:2.0
                    ports:
                    - containerPort: 8080
            ---
            apiVersion: v1
            kind: Service
            metadata:
              name: report-generator
            spec:
              selector:
                app: report-generator
                version: blue
              ports:
              - port: 80
                targetPort: 8080
    - id: warmup_3
      concept: "Pod Disruption Budgets"
      variants:
        - id: v1
          title: "PDB with minAvailable (Absolute)"
          description: >-
            Write a PodDisruptionBudget named <code>web-app-pdb</code> that requires at least <code>2</code>
            Pods with label <code>app: web-app</code> to remain available during voluntary disruptions.
          hints:
            - "Use <code>apiVersion: policy/v1</code> and <code>kind: PodDisruptionBudget</code>."
            - "<code>minAvailable: 2</code> means at least 2 Pods must be running at all times."
            - "The <code>selector.matchLabels</code> must match the Pods you want to protect."
          solution: |-
            apiVersion: policy/v1
            kind: PodDisruptionBudget
            metadata:
              name: web-app-pdb
            spec:
              minAvailable: 2
              selector:
                matchLabels:
                  app: web-app
        - id: v2
          title: "PDB with maxUnavailable (Absolute)"
          description: >-
            Write a PodDisruptionBudget named <code>api-pdb</code> that allows at most <code>1</code> Pod with
            label <code>app: api-server</code> to be unavailable during voluntary disruptions.
          hints:
            - "Use <code>maxUnavailable: 1</code> instead of <code>minAvailable</code>."
            - "You can specify either minAvailable or maxUnavailable, but not both."
            - "maxUnavailable is often simpler because it scales automatically with replica count."
          solution: |-
            apiVersion: policy/v1
            kind: PodDisruptionBudget
            metadata:
              name: api-pdb
            spec:
              maxUnavailable: 1
              selector:
                matchLabels:
                  app: api-server
        - id: v3
          title: "PDB with minAvailable Percentage"
          description: >-
            Write a PodDisruptionBudget named <code>frontend-pdb</code> that requires at least <code>80%</code>
            of Pods with label <code>app: frontend</code> to remain available.
          hints:
            - "Percentage values are strings in YAML: <code>minAvailable: \"80%\"</code>."
            - "With 5 replicas and 80%, at least 4 must remain available (ceiling of 5 * 0.80)."
            - "Percentages adapt automatically when you scale the Deployment."
          solution: |-
            apiVersion: policy/v1
            kind: PodDisruptionBudget
            metadata:
              name: frontend-pdb
            spec:
              minAvailable: "80%"
              selector:
                matchLabels:
                  app: frontend
        - id: v4
          title: "PDB with maxUnavailable Percentage"
          description: >-
            Write a PodDisruptionBudget named <code>worker-pdb</code> that allows at most <code>25%</code> of
            Pods with label <code>app: worker</code> to be unavailable.
          hints:
            - "<code>maxUnavailable: \"25%\"</code> allows a quarter of Pods to be disrupted."
            - "With 8 replicas, up to 2 Pods can be evicted simultaneously."
            - "This is a good default for most stateless services."
          solution: |-
            apiVersion: policy/v1
            kind: PodDisruptionBudget
            metadata:
              name: worker-pdb
            spec:
              maxUnavailable: "25%"
              selector:
                matchLabels:
                  app: worker
        - id: v5
          title: "PDB for Kafka Cluster"
          description: >-
            Write a PodDisruptionBudget named <code>kafka-pdb</code> for a 5-broker Kafka cluster with label
            <code>app: kafka</code>. Allow at most <code>1</code> broker to be unavailable to maintain quorum.
          hints:
            - "Kafka requires a majority of brokers to maintain quorum."
            - "<code>maxUnavailable: 1</code> ensures at least 4 of 5 brokers are always running."
            - "This prevents node drains from taking down too many brokers simultaneously."
          solution: |-
            apiVersion: policy/v1
            kind: PodDisruptionBudget
            metadata:
              name: kafka-pdb
            spec:
              maxUnavailable: 1
              selector:
                matchLabels:
                  app: kafka
        - id: v6
          title: "PDB for ZooKeeper (Strict Quorum)"
          description: >-
            Write a PodDisruptionBudget named <code>zk-pdb</code> for a 3-node ZooKeeper ensemble with label
            <code>app: zookeeper</code>. Set <code>minAvailable: 2</code> to maintain quorum (majority of 3).
          hints:
            - "ZooKeeper requires a strict majority for quorum: 2 out of 3 nodes."
            - "<code>minAvailable: 2</code> ensures that at most 1 node can be evicted at a time."
            - "This prevents cluster upgrades from accidentally losing ZooKeeper quorum."
          solution: |-
            apiVersion: policy/v1
            kind: PodDisruptionBudget
            metadata:
              name: zk-pdb
            spec:
              minAvailable: 2
              selector:
                matchLabels:
                  app: zookeeper
        - id: v7
          title: "PDB Blocking All Disruptions"
          description: >-
            Write a PodDisruptionBudget named <code>critical-db-pdb</code> for a single-replica database
            (<code>app: critical-db</code>) that blocks all voluntary disruptions by setting
            <code>maxUnavailable: 0</code>.
          hints:
            - "<code>maxUnavailable: 0</code> means no Pods can be evicted."
            - "This blocks node drains indefinitely until someone manually intervenes."
            - "Use this only for truly critical services where any disruption is unacceptable."
          solution: |-
            apiVersion: policy/v1
            kind: PodDisruptionBudget
            metadata:
              name: critical-db-pdb
            spec:
              maxUnavailable: 0
              selector:
                matchLabels:
                  app: critical-db
        - id: v8
          title: "PDB for StatefulSet (etcd)"
          description: >-
            Write a PodDisruptionBudget named <code>etcd-pdb</code> for a 3-member etcd cluster with label
            <code>app: etcd</code>. Use <code>minAvailable: 2</code> to maintain etcd quorum during node
            maintenance.
          hints:
            - "etcd, like ZooKeeper, needs a majority of members running."
            - "PDBs work with StatefulSets the same way as Deployments - they match by label."
            - "During a rolling cluster upgrade, only one etcd Pod is disrupted at a time."
          solution: |-
            apiVersion: policy/v1
            kind: PodDisruptionBudget
            metadata:
              name: etcd-pdb
            spec:
              minAvailable: 2
              selector:
                matchLabels:
                  app: etcd
        - id: v9
          title: "PDB with matchExpressions Selector"
          description: >-
            Write a PodDisruptionBudget named <code>backend-pdb</code> that protects all Pods where the label
            <code>tier</code> is either <code>backend</code> or <code>middleware</code>. Allow at most
            <code>1</code> Pod to be unavailable.
          hints:
            - "Use <code>matchExpressions</code> with the <code>In</code> operator instead of <code>matchLabels</code>."
            - "<code>matchExpressions</code> allows OR logic: tier In [backend, middleware]."
            - "This single PDB protects Pods across multiple Deployment groups."
          solution: |-
            apiVersion: policy/v1
            kind: PodDisruptionBudget
            metadata:
              name: backend-pdb
            spec:
              maxUnavailable: 1
              selector:
                matchExpressions:
                - key: tier
                  operator: In
                  values:
                  - backend
                  - middleware
        - id: v10
          title: "PDB with Deployment and Service"
          description: >-
            Write a complete setup: a Deployment named <code>cache</code> with <code>3</code> replicas using
            image <code>redis:7</code> on port <code>6379</code>, a Service named <code>cache</code>, and a
            PDB named <code>cache-pdb</code> with <code>minAvailable: 2</code>. All resources should use the
            label <code>app: cache</code>.
          hints:
            - "The PDB selector must match the same labels as the Deployment's Pod template."
            - "All three resources reference the same <code>app: cache</code> label."
            - "With 3 replicas and minAvailable: 2, only 1 Pod can be disrupted at a time."
          solution: |-
            apiVersion: apps/v1
            kind: Deployment
            metadata:
              name: cache
            spec:
              replicas: 3
              selector:
                matchLabels:
                  app: cache
              template:
                metadata:
                  labels:
                    app: cache
                spec:
                  containers:
                  - name: redis
                    image: redis:7
                    ports:
                    - containerPort: 6379
            ---
            apiVersion: v1
            kind: Service
            metadata:
              name: cache
            spec:
              selector:
                app: cache
              ports:
              - port: 6379
                targetPort: 6379
            ---
            apiVersion: policy/v1
            kind: PodDisruptionBudget
            metadata:
              name: cache-pdb
            spec:
              minAvailable: 2
              selector:
                matchLabels:
                  app: cache
        - id: v11
          title: "PDB for High-Availability Web Tier"
          description: >-
            Write a PDB named <code>ha-web-pdb</code> for a high-availability web tier (<code>app: ha-web</code>)
            with <code>10</code> replicas. Use <code>maxUnavailable: "20%"</code> to allow up to 2 Pods to be
            disrupted during rolling cluster upgrades.
          hints:
            - "With 10 replicas and 20%, up to 2 Pods can be evicted simultaneously."
            - "This is a good balance for large deployments during cluster maintenance."
            - "maxUnavailable percentage is often preferred over absolute values for scalable services."
          solution: |-
            apiVersion: policy/v1
            kind: PodDisruptionBudget
            metadata:
              name: ha-web-pdb
            spec:
              maxUnavailable: "20%"
              selector:
                matchLabels:
                  app: ha-web
  challenges:
    - id: challenge_1
      block: 1
      difficulty: 2
      concept: "Strategy Comparison"
      variants:
        - id: v1
          title: "Zero-Downtime API with Instant Rollback"
          description: >-
            You are deploying a critical payment API that must have zero downtime and needs the ability to
            instantly roll back if something goes wrong. The cluster has plenty of spare resources. Write the
            Deployment strategy (or strategies) and any supporting resources to meet these requirements.
            Use app name <code>payment-api</code>, <code>4</code> replicas, image <code>payment:2.0</code>.
          functionSignature: "Blue-Green Deployment"
          testCases:
            - input: "Requirement: zero downtime"
              output: "Both blue and green Deployments are running simultaneously"
            - input: "Requirement: instant rollback"
              output: "Service selector can be patched back to blue immediately"
            - input: "During deployment: how many total Pods?"
              output: "8 Pods (4 blue + 4 green)"
          hints:
            - title: "Think about it"
              content: >-
                Which strategy provides both zero downtime AND instant rollback? Rolling updates have slow
                rollbacks (undo rollout). Recreate has downtime. Which leaves...
            - title: "Hint"
              content: >-
                Blue-green deployments give instant rollback by switching the Service selector. Deploy the new
                version as a separate Deployment, test it, then switch the Service.
            - title: "Pattern"
              content: |-
                <pre>1. Blue Deployment (current) with version: blue label
                2. Green Deployment (new) with version: green label
                3. Service selects version: blue initially
                4. Switch to green after testing
                5. Rollback: patch selector back to blue</pre>
          solution: |-
            apiVersion: apps/v1
            kind: Deployment
            metadata:
              name: payment-api-blue
            spec:
              replicas: 4
              selector:
                matchLabels:
                  app: payment-api
                  version: blue
              template:
                metadata:
                  labels:
                    app: payment-api
                    version: blue
                spec:
                  containers:
                  - name: api
                    image: payment:1.0
                    ports:
                    - containerPort: 8080
            ---
            apiVersion: apps/v1
            kind: Deployment
            metadata:
              name: payment-api-green
            spec:
              replicas: 4
              selector:
                matchLabels:
                  app: payment-api
                  version: green
              template:
                metadata:
                  labels:
                    app: payment-api
                    version: green
                spec:
                  containers:
                  - name: api
                    image: payment:2.0
                    ports:
                    - containerPort: 8080
            ---
            apiVersion: v1
            kind: Service
            metadata:
              name: payment-api
            spec:
              selector:
                app: payment-api
                version: blue
              ports:
              - port: 80
                targetPort: 8080
          difficulty: 1
        - id: v2
          title: "Resource-Constrained Worker Update"
          description: >-
            You have a <code>data-worker</code> Deployment with <code>8</code> replicas (image
            <code>worker:3.0</code>) on a cluster with very limited spare resources. You cannot run more than
            8 Pods at any time, but you can tolerate 1 Pod being unavailable briefly. Choose and implement the
            right rolling update strategy.
          functionSignature: "RollingUpdate (maxSurge=0)"
          testCases:
            - input: "Maximum Pods during rollout"
              output: "8 (never exceeds desired count)"
            - input: "Minimum available Pods during rollout"
              output: "7 (maxUnavailable=1)"
            - input: "How does each step work?"
              output: "Kill 1 old Pod, wait for 1 new Pod to be Ready, repeat"
          hints:
            - title: "Think about it"
              content: >-
                If you cannot run extra Pods (no surge), what is the only way to make progress? You must remove
                an old Pod before creating a new one.
            - title: "Hint"
              content: >-
                Set <code>maxSurge: 0</code> so no extra Pods are created, and <code>maxUnavailable: 1</code>
                so one old Pod is killed to make room for a new one.
            - title: "Pattern"
              content: |-
                <pre>strategy:
                  type: RollingUpdate
                  rollingUpdate:
                    maxSurge: 0         # no extra Pods
                    maxUnavailable: 1   # kill one, start one</pre>
          solution: |-
            apiVersion: apps/v1
            kind: Deployment
            metadata:
              name: data-worker
            spec:
              replicas: 8
              strategy:
                type: RollingUpdate
                rollingUpdate:
                  maxSurge: 0
                  maxUnavailable: 1
              selector:
                matchLabels:
                  app: data-worker
              template:
                metadata:
                  labels:
                    app: data-worker
                spec:
                  containers:
                  - name: worker
                    image: worker:3.0
                    ports:
                    - containerPort: 8080
          difficulty: 1
        - id: v3
          title: "Single-Instance Database Migration"
          description: >-
            You have a legacy application <code>legacy-app</code> (1 replica, image <code>legacy:5.0</code>)
            that runs database schema migrations on startup. The old and new versions are incompatible because
            the schema changes break the old code. Only one instance can run at a time. Choose and implement the
            correct strategy.
          functionSignature: "Recreate Strategy"
          testCases:
            - input: "Can old and new Pods coexist?"
              output: "No, schema migration makes them incompatible"
            - input: "Is downtime acceptable?"
              output: "Yes, brief downtime is acceptable for a schema migration"
            - input: "What happens during the update?"
              output: "All old Pods are terminated, then new Pods are created"
          hints:
            - title: "Think about it"
              content: >-
                If old and new versions cannot coexist, RollingUpdate is not safe (it runs both simultaneously).
                Blue-green is also risky because both versions would be running. What strategy kills old Pods
                first?
            - title: "Hint"
              content: >-
                The <code>Recreate</code> strategy terminates all old Pods before creating new ones. This
                guarantees no overlap between versions.
            - title: "Pattern"
              content: |-
                <pre>strategy:
                  type: Recreate
                # No rollingUpdate section needed</pre>
          solution: |-
            apiVersion: apps/v1
            kind: Deployment
            metadata:
              name: legacy-app
            spec:
              replicas: 1
              strategy:
                type: Recreate
              selector:
                matchLabels:
                  app: legacy-app
              template:
                metadata:
                  labels:
                    app: legacy-app
                spec:
                  containers:
                  - name: app
                    image: legacy:5.0
                    ports:
                    - containerPort: 5000
          difficulty: 1
        - id: v4
          title: "Gradual Validation with Real Traffic"
          description: >-
            You want to deploy <code>recommendation-svc</code> (image <code>reco:2.0</code>) gradually, sending
            only 10% of real traffic to the new version first while 90% stays on the stable version. You have
            <code>10</code> total replicas. Implement a native Kubernetes canary using replica ratios.
          functionSignature: "Canary Deployment (Replica Ratio)"
          testCases:
            - input: "Total replicas across both Deployments"
              output: "10 (9 stable + 1 canary)"
            - input: "Approximate traffic to canary"
              output: "~10% (1 out of 10 Pods)"
            - input: "Service selector"
              output: "Only selects on app label, matching both Deployments"
          hints:
            - title: "Think about it"
              content: >-
                With native Kubernetes Services, traffic is distributed roughly evenly across all matching Pods.
                To get ~10% canary traffic, how many Pods of each version do you need?
            - title: "Hint"
              content: >-
                Create two Deployments sharing the same <code>app</code> label. The stable has 9 replicas, the
                canary has 1 replica. The Service selects only on the shared <code>app</code> label.
            - title: "Pattern"
              content: |-
                <pre>1. Stable Deployment: 9 replicas, labels: app=web, track=stable
                2. Canary Deployment: 1 replica, labels: app=web, track=canary
                3. Service: selector: app=web (matches both)
                4. ~10% traffic goes to canary via Pod ratio</pre>
          solution: |-
            apiVersion: apps/v1
            kind: Deployment
            metadata:
              name: reco-stable
            spec:
              replicas: 9
              selector:
                matchLabels:
                  app: recommendation-svc
                  track: stable
              template:
                metadata:
                  labels:
                    app: recommendation-svc
                    track: stable
                spec:
                  containers:
                  - name: reco
                    image: reco:1.0
                    ports:
                    - containerPort: 8080
            ---
            apiVersion: apps/v1
            kind: Deployment
            metadata:
              name: reco-canary
            spec:
              replicas: 1
              selector:
                matchLabels:
                  app: recommendation-svc
                  track: canary
              template:
                metadata:
                  labels:
                    app: recommendation-svc
                    track: canary
                spec:
                  containers:
                  - name: reco
                    image: reco:2.0
                    ports:
                    - containerPort: 8080
            ---
            apiVersion: v1
            kind: Service
            metadata:
              name: recommendation-svc
            spec:
              selector:
                app: recommendation-svc
              ports:
              - port: 80
                targetPort: 8080
          difficulty: 2
        - id: v5
          title: "Safe Rolling Update with PDB Protection"
          description: >-
            Deploy <code>inventory-svc</code> with <code>6</code> replicas (image <code>inventory:3.0</code>)
            using a safe rolling update (<code>maxSurge: 1</code>, <code>maxUnavailable: 0</code>,
            <code>minReadySeconds: 20</code>). Also create a PDB that ensures at least 4 Pods are always
            available during node drains.
          functionSignature: "RollingUpdate + PodDisruptionBudget"
          testCases:
            - input: "Minimum available during rolling update"
              output: "6 (maxUnavailable=0 keeps all replicas available)"
            - input: "Minimum available during node drain"
              output: "4 (PDB minAvailable=4)"
            - input: "Allowed disruptions for PDB"
              output: "2 (6 running - 4 minimum = 2 allowed)"
          hints:
            - title: "Think about it"
              content: >-
                The Deployment strategy protects you during rollouts. The PDB protects you during node drains
                and cluster upgrades. You need both for full protection.
            - title: "Hint"
              content: >-
                The PDB selector must match the Deployment's Pod labels. Set <code>minAvailable: 4</code> to
                allow 2 Pods to be evicted simultaneously during maintenance.
            - title: "Pattern"
              content: |-
                <pre>1. Deployment with safe rolling update strategy
                2. PDB with minAvailable matching your SLO
                3. Both use the same label selector (app: inventory-svc)</pre>
          solution: |-
            apiVersion: apps/v1
            kind: Deployment
            metadata:
              name: inventory-svc
            spec:
              replicas: 6
              minReadySeconds: 20
              strategy:
                type: RollingUpdate
                rollingUpdate:
                  maxSurge: 1
                  maxUnavailable: 0
              selector:
                matchLabels:
                  app: inventory-svc
              template:
                metadata:
                  labels:
                    app: inventory-svc
                spec:
                  containers:
                  - name: inventory
                    image: inventory:3.0
                    ports:
                    - containerPort: 8080
            ---
            apiVersion: policy/v1
            kind: PodDisruptionBudget
            metadata:
              name: inventory-svc-pdb
            spec:
              minAvailable: 4
              selector:
                matchLabels:
                  app: inventory-svc
          difficulty: 2
        - id: v6
          title: "GPU Workload Strategy"
          description: >-
            You have a GPU-based ML inference service <code>ml-inference</code> (2 replicas, image
            <code>inference:2.0</code>). GPUs are scarce and you cannot run any extra Pods during the update.
            The team accepts brief downtime during deploys. Choose and implement the right strategy with a
            PDB that blocks node drains to prevent accidental disruption.
          functionSignature: "Recreate + Strict PDB"
          testCases:
            - input: "Can you run old and new Pods simultaneously?"
              output: "No, GPU resources are fully allocated"
            - input: "Strategy type"
              output: "Recreate (kill all, then create new)"
            - input: "PDB during node drain"
              output: "maxUnavailable: 0 blocks all voluntary evictions"
          hints:
            - title: "Think about it"
              content: >-
                With no spare GPU resources, you cannot run extra Pods. The only option is to stop old Pods
                before starting new ones. And since GPU Pods are precious, you want a PDB to block node drains.
            - title: "Hint"
              content: >-
                Use <code>Recreate</code> for the Deployment strategy. Add a PDB with
                <code>maxUnavailable: 0</code> to prevent node drains from disrupting the GPU Pods.
            - title: "Pattern"
              content: |-
                <pre>1. Deployment with strategy: Recreate (accepts downtime)
                2. PDB with maxUnavailable: 0 (blocks node drains)
                3. GPU resources in container spec</pre>
          solution: |-
            apiVersion: apps/v1
            kind: Deployment
            metadata:
              name: ml-inference
            spec:
              replicas: 2
              strategy:
                type: Recreate
              selector:
                matchLabels:
                  app: ml-inference
              template:
                metadata:
                  labels:
                    app: ml-inference
                spec:
                  containers:
                  - name: inference
                    image: inference:2.0
                    ports:
                    - containerPort: 8080
                    resources:
                      limits:
                        nvidia.com/gpu: 1
            ---
            apiVersion: policy/v1
            kind: PodDisruptionBudget
            metadata:
              name: ml-inference-pdb
            spec:
              maxUnavailable: 0
              selector:
                matchLabels:
                  app: ml-inference
          difficulty: 3
        - id: v7
          title: "Feature Testing by User Segment (A/B)"
          description: >-
            You want to A/B test a new version of <code>search-svc</code> by routing requests with the header
            <code>X-Beta: true</code> to the canary version. Write a stable Deployment
            (<code>search-stable</code>, 3 replicas, <code>search:1.0</code>), a canary Deployment
            (<code>search-canary</code>, 1 replica, <code>search:2.0</code>), the main Ingress, and the canary
            Ingress with nginx canary-by-header annotations.
          functionSignature: "A/B Testing (nginx Ingress)"
          testCases:
            - input: "Request without header"
              output: "Routes to stable (search:1.0)"
            - input: "Request with X-Beta: true header"
              output: "Routes to canary (search:2.0)"
            - input: "Required Ingress annotation"
              output: "nginx.ingress.kubernetes.io/canary: 'true' and canary-by-header"
          hints:
            - title: "Think about it"
              content: >-
                A/B testing routes specific users to the new version based on criteria like headers. nginx
                Ingress Controller supports this via canary annotations.
            - title: "Hint"
              content: >-
                Create a main Ingress for stable traffic and a second Ingress with
                <code>nginx.ingress.kubernetes.io/canary: "true"</code> and
                <code>canary-by-header: "X-Beta"</code> pointing to the canary Service.
            - title: "Pattern"
              content: |-
                <pre>1. Stable Deployment + Service
                2. Canary Deployment + Service
                3. Main Ingress  stable Service
                4. Canary Ingress (with canary annotations)  canary Service
                5. Header "X-Beta: true"  canary</pre>
          solution: |-
            apiVersion: apps/v1
            kind: Deployment
            metadata:
              name: search-stable
            spec:
              replicas: 3
              selector:
                matchLabels:
                  app: search-svc
                  track: stable
              template:
                metadata:
                  labels:
                    app: search-svc
                    track: stable
                spec:
                  containers:
                  - name: search
                    image: search:1.0
                    ports:
                    - containerPort: 8080
            ---
            apiVersion: apps/v1
            kind: Deployment
            metadata:
              name: search-canary
            spec:
              replicas: 1
              selector:
                matchLabels:
                  app: search-svc
                  track: canary
              template:
                metadata:
                  labels:
                    app: search-svc
                    track: canary
                spec:
                  containers:
                  - name: search
                    image: search:2.0
                    ports:
                    - containerPort: 8080
            ---
            apiVersion: v1
            kind: Service
            metadata:
              name: search-stable
            spec:
              selector:
                app: search-svc
                track: stable
              ports:
              - port: 80
                targetPort: 8080
            ---
            apiVersion: v1
            kind: Service
            metadata:
              name: search-canary
            spec:
              selector:
                app: search-svc
                track: canary
              ports:
              - port: 80
                targetPort: 8080
            ---
            apiVersion: networking.k8s.io/v1
            kind: Ingress
            metadata:
              name: search-main
            spec:
              ingressClassName: nginx
              rules:
              - host: search.example.com
                http:
                  paths:
                  - path: /
                    pathType: Prefix
                    backend:
                      service:
                        name: search-stable
                        port:
                          number: 80
            ---
            apiVersion: networking.k8s.io/v1
            kind: Ingress
            metadata:
              name: search-canary
              annotations:
                nginx.ingress.kubernetes.io/canary: "true"
                nginx.ingress.kubernetes.io/canary-by-header: "X-Beta"
                nginx.ingress.kubernetes.io/canary-by-header-value: "true"
            spec:
              ingressClassName: nginx
              rules:
              - host: search.example.com
                http:
                  paths:
                  - path: /
                    pathType: Prefix
                    backend:
                      service:
                        name: search-canary
                        port:
                          number: 80
          difficulty: 3
    - id: challenge_2
      block: 2
      difficulty: 3
      concept: "Canary Deployments"
      variants:
        - id: v1
          title: "Canary with 20% Traffic via Replica Ratio"
          description: >-
            Implement a native Kubernetes canary for <code>product-svc</code> where approximately 20% of
            traffic goes to the canary version. You have a budget of <code>5</code> total replicas. The stable
            version runs <code>product:1.0</code> and the canary runs <code>product:2.0</code>. Write both
            Deployments and the Service.
          functionSignature: "Canary (4 stable + 1 canary)"
          testCases:
            - input: "Stable replicas"
              output: "4"
            - input: "Canary replicas"
              output: "1"
            - input: "Approximate canary traffic percentage"
              output: "~20% (1 out of 5 Pods)"
          hints:
            - title: "Think about it"
              content: >-
                With native K8s Services, each Pod gets roughly equal traffic. To get ~20% canary, you need
                1 canary Pod for every 4 stable Pods.
            - title: "Hint"
              content: >-
                Both Deployments share the same <code>app</code> label. The Service selects only on
                <code>app</code>, so traffic reaches both stable and canary Pods.
            - title: "Pattern"
              content: |-
                <pre>Stable: 4 replicas (app=product-svc, track=stable)
                Canary: 1 replica  (app=product-svc, track=canary)
                Service: selector: app=product-svc (matches all 5 Pods)</pre>
          solution: |-
            apiVersion: apps/v1
            kind: Deployment
            metadata:
              name: product-stable
            spec:
              replicas: 4
              selector:
                matchLabels:
                  app: product-svc
                  track: stable
              template:
                metadata:
                  labels:
                    app: product-svc
                    track: stable
                spec:
                  containers:
                  - name: product
                    image: product:1.0
                    ports:
                    - containerPort: 8080
            ---
            apiVersion: apps/v1
            kind: Deployment
            metadata:
              name: product-canary
            spec:
              replicas: 1
              selector:
                matchLabels:
                  app: product-svc
                  track: canary
              template:
                metadata:
                  labels:
                    app: product-svc
                    track: canary
                spec:
                  containers:
                  - name: product
                    image: product:2.0
                    ports:
                    - containerPort: 8080
            ---
            apiVersion: v1
            kind: Service
            metadata:
              name: product-svc
            spec:
              selector:
                app: product-svc
              ports:
              - port: 80
                targetPort: 8080
          difficulty: 3
        - id: v2
          title: "Canary with Gateway API Traffic Splitting (5%)"
          description: >-
            Implement a canary for <code>checkout-svc</code> using Gateway API HTTPRoute to send exactly 5% of
            traffic to the canary. The stable Service is <code>checkout-stable</code> and the canary Service is
            <code>checkout-canary</code>. Use the gateway named <code>main-gateway</code> and hostname
            <code>checkout.example.com</code>.
          functionSignature: "HTTPRoute weight-based split"
          testCases:
            - input: "Stable traffic weight"
              output: "95"
            - input: "Canary traffic weight"
              output: "5"
            - input: "Is traffic split independent of replica count?"
              output: "Yes, Gateway API uses explicit weights"
          hints:
            - title: "Think about it"
              content: >-
                Native K8s canary is limited to replica ratios. For exact 5% traffic, you need a traffic
                management layer. Gateway API HTTPRoute supports weight-based splitting.
            - title: "Hint"
              content: >-
                Write an HTTPRoute with <code>backendRefs</code> listing both Services with
                <code>weight: 95</code> and <code>weight: 5</code>.
            - title: "Pattern"
              content: |-
                <pre>apiVersion: gateway.networking.k8s.io/v1
                kind: HTTPRoute
                spec:
                  rules:
                  - backendRefs:
                    - name: stable-svc
                      weight: 95
                    - name: canary-svc
                      weight: 5</pre>
          solution: |-
            apiVersion: gateway.networking.k8s.io/v1
            kind: HTTPRoute
            metadata:
              name: checkout-canary
            spec:
              parentRefs:
              - name: main-gateway
              hostnames:
              - "checkout.example.com"
              rules:
              - backendRefs:
                - name: checkout-stable
                  port: 80
                  weight: 95
                - name: checkout-canary
                  port: 80
                  weight: 5
          difficulty: 3
        - id: v3
          title: "Canary Promotion: Scale from 10% to 50% to 100%"
          description: >-
            You have a canary running at ~10% (1 canary replica, 9 stable replicas) for <code>feed-svc</code>.
            The canary looks healthy. Write the <code>kubectl scale</code> commands to promote it to ~50%
            traffic, then to 100%. Keep the total replica count at 10 throughout.
          functionSignature: "kubectl scale commands"
          testCases:
            - input: "Step 1: ~10% canary"
              output: "stable=9, canary=1"
            - input: "Step 2: ~50% canary"
              output: "stable=5, canary=5"
            - input: "Step 3: 100% canary"
              output: "stable=0, canary=10"
          hints:
            - title: "Think about it"
              content: >-
                With replica-ratio canary, changing the traffic split means scaling the two Deployments. To
                maintain capacity, the total should stay at 10.
            - title: "Hint"
              content: >-
                Use <code>kubectl scale deployment feed-stable --replicas=5</code> and
                <code>kubectl scale deployment feed-canary --replicas=5</code> for 50%.
            - title: "Pattern"
              content: |-
                <pre># 50% canary
                kubectl scale deployment feed-stable --replicas=5
                kubectl scale deployment feed-canary --replicas=5

                # 100% canary (full promotion)
                kubectl scale deployment feed-stable --replicas=0
                kubectl scale deployment feed-canary --replicas=10</pre>
          solution: |-
            # Promote to ~50% canary:
            # kubectl scale deployment feed-stable --replicas=5
            # kubectl scale deployment feed-canary --replicas=5

            # Promote to 100% canary (full rollout):
            # kubectl scale deployment feed-stable --replicas=0
            # kubectl scale deployment feed-canary --replicas=10

            # After full promotion, update stable image and reset:
            # kubectl set image deployment/feed-stable feed=feed:2.0
            # kubectl scale deployment feed-stable --replicas=10
            # kubectl scale deployment feed-canary --replicas=0
          difficulty: 3
        - id: v4
          title: "Canary with Gateway API (Gradual Ramp: 5% -> 25% -> 75% -> 100%)"
          description: >-
            Write the Gateway API HTTPRoute for <code>api-svc</code> at each stage of a canary ramp. Start at
            5% canary, then show the patched HTTPRoute at 25%, 75%, and 100%. Use gateway
            <code>main-gateway</code>, hostname <code>api.example.com</code>, stable Service
            <code>api-stable</code>, canary Service <code>api-canary</code>.
          functionSignature: "HTTPRoute weight progression"
          testCases:
            - input: "Stage 1 weights"
              output: "stable=95, canary=5"
            - input: "Stage 2 weights"
              output: "stable=75, canary=25"
            - input: "Stage 3 weights"
              output: "stable=25, canary=75"
            - input: "Stage 4 (full promotion)"
              output: "stable=0, canary=100"
          hints:
            - title: "Think about it"
              content: >-
                Gateway API traffic splitting is independent of replica counts. You just change the weight
                values in the HTTPRoute to shift traffic.
            - title: "Hint"
              content: >-
                Patch the HTTPRoute at each stage by changing the <code>weight</code> values in
                <code>backendRefs</code>. The weights don't need to sum to 100 (Kubernetes normalizes them)
                but it's conventional.
            - title: "Pattern"
              content: |-
                <pre>Stage 1: weight: 95 / weight: 5
                Stage 2: weight: 75 / weight: 25
                Stage 3: weight: 25 / weight: 75
                Stage 4: weight: 0  / weight: 100</pre>
          solution: |-
            # Stage 1: 5% canary
            apiVersion: gateway.networking.k8s.io/v1
            kind: HTTPRoute
            metadata:
              name: api-canary-route
            spec:
              parentRefs:
              - name: main-gateway
              hostnames:
              - "api.example.com"
              rules:
              - backendRefs:
                - name: api-stable
                  port: 80
                  weight: 95
                - name: api-canary
                  port: 80
                  weight: 5
            ---
            # Stage 2: 25% canary
            # kubectl patch httproute api-canary-route --type=merge -p '
            # spec:
            #   rules:
            #   - backendRefs:
            #     - name: api-stable
            #       port: 80
            #       weight: 75
            #     - name: api-canary
            #       port: 80
            #       weight: 25
            # '
            ---
            # Stage 3: 75% canary
            # kubectl patch httproute api-canary-route --type=merge -p '
            # spec:
            #   rules:
            #   - backendRefs:
            #     - name: api-stable
            #       port: 80
            #       weight: 25
            #     - name: api-canary
            #       port: 80
            #       weight: 75
            # '
            ---
            # Stage 4: 100% canary (full promotion)
            # kubectl patch httproute api-canary-route --type=merge -p '
            # spec:
            #   rules:
            #   - backendRefs:
            #     - name: api-stable
            #       port: 80
            #       weight: 0
            #     - name: api-canary
            #       port: 80
            #       weight: 100
            # '
          difficulty: 4
        - id: v5
          title: "Argo Rollouts Canary with Steps"
          description: >-
            Write an Argo Rollouts <code>Rollout</code> resource for <code>web-app</code> with <code>10</code>
            replicas using image <code>webapp:3.0</code>. Configure a canary strategy with these steps: set
            weight to 10%, pause for 2 minutes, set weight to 30%, pause for 5 minutes, set weight to 60%,
            pause for 5 minutes, then set weight to 100%. Use <code>web-app-stable</code> and
            <code>web-app-canary</code> as Service names.
          functionSignature: "Argo Rollout with canary steps"
          testCases:
            - input: "apiVersion"
              output: "argoproj.io/v1alpha1"
            - input: "kind"
              output: "Rollout"
            - input: "Number of canary steps"
              output: "7 (setWeight, pause, setWeight, pause, setWeight, pause, setWeight)"
          hints:
            - title: "Think about it"
              content: >-
                Argo Rollouts replaces Deployment with a Rollout CRD. The canary steps define an automated
                progression of traffic shifts and pauses.
            - title: "Hint"
              content: >-
                The <code>strategy.canary.steps</code> array uses <code>setWeight</code> and <code>pause</code>
                entries. Pauses use <code>{duration: 2m}</code> syntax.
            - title: "Pattern"
              content: |-
                <pre>strategy:
                  canary:
                    stableService: web-app-stable
                    canaryService: web-app-canary
                    steps:
                    - setWeight: 10
                    - pause: {duration: 2m}
                    - setWeight: 30
                    ...</pre>
          solution: |-
            apiVersion: argoproj.io/v1alpha1
            kind: Rollout
            metadata:
              name: web-app
            spec:
              replicas: 10
              revisionHistoryLimit: 3
              selector:
                matchLabels:
                  app: web-app
              strategy:
                canary:
                  stableService: web-app-stable
                  canaryService: web-app-canary
                  steps:
                  - setWeight: 10
                  - pause: {duration: 2m}
                  - setWeight: 30
                  - pause: {duration: 5m}
                  - setWeight: 60
                  - pause: {duration: 5m}
                  - setWeight: 100
              template:
                metadata:
                  labels:
                    app: web-app
                spec:
                  containers:
                  - name: app
                    image: webapp:3.0
                    ports:
                    - containerPort: 8080
          difficulty: 4
        - id: v6
          title: "Argo Rollouts Canary with Analysis"
          description: >-
            Write an Argo Rollouts <code>Rollout</code> for <code>api-gateway</code> (5 replicas, image
            <code>gateway:2.0</code>) with canary steps that include an AnalysisTemplate. Steps: set weight
            to 10%, run analysis <code>success-rate</code>, set weight to 50%, pause 5 minutes, set weight
            to 100%. Also write the AnalysisTemplate that checks Prometheus for a success rate >= 99%.
          functionSignature: "Rollout + AnalysisTemplate"
          testCases:
            - input: "Analysis success condition"
              output: "result[0] >= 0.99"
            - input: "Analysis failure limit"
              output: "2 (allows 2 failed checks before aborting)"
            - input: "If analysis fails, what happens?"
              output: "Rollout is automatically aborted and canary is scaled down"
          hints:
            - title: "Think about it"
              content: >-
                Argo Rollouts can automatically promote or abort based on metric analysis. The
                AnalysisTemplate defines what to measure and what thresholds to use.
            - title: "Hint"
              content: >-
                Use <code>- analysis: {templates: [{templateName: success-rate}]}</code> in the Rollout steps.
                The AnalysisTemplate uses a Prometheus provider to check HTTP success rate.
            - title: "Pattern"
              content: |-
                <pre>Rollout steps:
                  - setWeight: 10
                  - analysis: {templates: [{templateName: success-rate}]}
                  - setWeight: 50
                  - pause: {duration: 5m}
                  - setWeight: 100

                AnalysisTemplate:
                  metrics:
                  - name: success-rate
                    successCondition: result[0] >= 0.99
                    provider: prometheus</pre>
          solution: |-
            apiVersion: argoproj.io/v1alpha1
            kind: Rollout
            metadata:
              name: api-gateway
            spec:
              replicas: 5
              revisionHistoryLimit: 3
              selector:
                matchLabels:
                  app: api-gateway
              strategy:
                canary:
                  stableService: api-gateway-stable
                  canaryService: api-gateway-canary
                  steps:
                  - setWeight: 10
                  - analysis:
                      templates:
                      - templateName: success-rate
                  - setWeight: 50
                  - pause: {duration: 5m}
                  - setWeight: 100
              template:
                metadata:
                  labels:
                    app: api-gateway
                spec:
                  containers:
                  - name: gateway
                    image: gateway:2.0
                    ports:
                    - containerPort: 8080
            ---
            apiVersion: argoproj.io/v1alpha1
            kind: AnalysisTemplate
            metadata:
              name: success-rate
            spec:
              metrics:
              - name: success-rate
                interval: 60s
                count: 5
                successCondition: result[0] >= 0.99
                failureLimit: 2
                provider:
                  prometheus:
                    address: http://prometheus.monitoring:9090
                    query: |
                      sum(rate(http_requests_total{app="api-gateway",status=~"2.."}[5m]))
                      /
                      sum(rate(http_requests_total{app="api-gateway"}[5m]))
          difficulty: 4
    - id: challenge_3
      block: 1
      difficulty: 2
      concept: "Rolling Updates"
      variants:
        - id: v1
          title: "Predict Rollout: 3 Replicas, maxSurge=1, maxUnavailable=0"
          description: >-
            A Deployment has <code>3</code> replicas running v1. A rolling update to v2 starts with
            <code>maxSurge: 1</code> and <code>maxUnavailable: 0</code>. List the state at each step: how
            many v1 Pods, how many v2 Pods, and total Pods. Describe the full progression until all Pods
            are v2.
          functionSignature: "Rolling update step-by-step"
          testCases:
            - input: "Start state"
              output: "3 v1, 0 v2, total=3"
            - input: "Step 1: create new Pod (surge)"
              output: "3 v1, 1 v2, total=4"
            - input: "Step 2: kill old Pod"
              output: "2 v1, 1 v2, total=3"
            - input: "Step 3: create new Pod"
              output: "2 v1, 2 v2, total=4"
            - input: "Step 4: kill old Pod"
              output: "1 v1, 2 v2, total=3"
            - input: "Step 5: create new Pod"
              output: "1 v1, 3 v2, total=4"
            - input: "Step 6: kill last old Pod"
              output: "0 v1, 3 v2, total=3"
          hints:
            - title: "Think about it"
              content: >-
                With maxUnavailable=0, Kubernetes can never drop below 3 available Pods. With maxSurge=1, it
                can have at most 4. So it creates 1 new, then kills 1 old, alternating.
            - title: "Hint"
              content: >-
                The pattern is: create  kill  create  kill  create  kill. At each create step, total=4.
                At each kill step, total=3. Available Pods never drop below 3.
            - title: "Pattern"
              content: |-
                <pre>Max Pods = replicas + maxSurge = 3 + 1 = 4
                Min Available = replicas - maxUnavailable = 3 - 0 = 3
                Pattern: create 1, kill 1, create 1, kill 1, create 1, kill 1</pre>
          solution: |-
            # Rolling update progression: 3 replicas, maxSurge=1, maxUnavailable=0
            #
            # Start:   [v1] [v1] [v1]            3 v1, 0 v2, total=3
            # Step 1:  [v1] [v1] [v1] [v2]       3 v1, 1 v2, total=4 (surge)
            # Step 2:  [v1] [v1] [] [v2]       2 v1, 1 v2, total=3 (kill old)
            # Step 3:  [v1] [v1] [v2] [v2]       2 v1, 2 v2, total=4 (surge)
            # Step 4:  [v1] [] [v2] [v2]       1 v1, 2 v2, total=3 (kill old)
            # Step 5:  [v1] [v2] [v2] [v2]       1 v1, 3 v2, total=4 (surge)
            # Step 6:  [] [v2] [v2] [v2]       0 v1, 3 v2, total=3 (kill old)
            # Done:    [v2] [v2] [v2]             0 v1, 3 v2, total=3
            #
            # Key constraints:
            # - Max total Pods at any time: 4 (replicas + maxSurge)
            # - Min available Pods at any time: 3 (replicas - maxUnavailable)
            # - Total steps: 6 (3 creates + 3 kills)
          difficulty: 2
        - id: v2
          title: "Predict Rollout: 4 Replicas, maxSurge=0, maxUnavailable=1"
          description: >-
            A Deployment has <code>4</code> replicas running v1. A rolling update to v2 starts with
            <code>maxSurge: 0</code> and <code>maxUnavailable: 1</code>. List the state at each step. Note:
            old Pods are killed first (no surge), then new Pods are created.
          functionSignature: "Rolling update step-by-step"
          testCases:
            - input: "Start state"
              output: "4 v1, 0 v2, total=4"
            - input: "Step 1: kill old Pod"
              output: "3 v1, 0 v2, total=3"
            - input: "Step 2: create new Pod"
              output: "3 v1, 1 v2, total=4"
            - input: "Final state"
              output: "0 v1, 4 v2, total=4"
          hints:
            - title: "Think about it"
              content: >-
                With maxSurge=0, no extra Pods can be created. The only way to make progress is to kill an old
                Pod first (maxUnavailable=1 allows one Pod to be down).
            - title: "Hint"
              content: >-
                The pattern is: kill  create  kill  create  kill  create  kill  create. At each kill
                step, total=3. At each create step, total=4. Available never drops below 3.
            - title: "Pattern"
              content: |-
                <pre>Max Pods = replicas + maxSurge = 4 + 0 = 4
                Min Available = replicas - maxUnavailable = 4 - 1 = 3
                Pattern: kill 1, create 1, kill 1, create 1, ...</pre>
          solution: |-
            # Rolling update progression: 4 replicas, maxSurge=0, maxUnavailable=1
            #
            # Start:   [v1] [v1] [v1] [v1]       4 v1, 0 v2, total=4
            # Step 1:  [] [v1] [v1] [v1]       3 v1, 0 v2, total=3 (kill old)
            # Step 2:  [v2] [v1] [v1] [v1]       3 v1, 1 v2, total=4 (create new)
            # Step 3:  [v2] [] [v1] [v1]       2 v1, 1 v2, total=3 (kill old)
            # Step 4:  [v2] [v2] [v1] [v1]       2 v1, 2 v2, total=4 (create new)
            # Step 5:  [v2] [v2] [] [v1]       1 v1, 2 v2, total=3 (kill old)
            # Step 6:  [v2] [v2] [v2] [v1]       1 v1, 3 v2, total=4 (create new)
            # Step 7:  [v2] [v2] [v2] []       0 v1, 3 v2, total=3 (kill old)
            # Step 8:  [v2] [v2] [v2] [v2]       0 v1, 4 v2, total=4 (create new)
            # Done:    [v2] [v2] [v2] [v2]       0 v1, 4 v2, total=4
            #
            # Key constraints:
            # - Max total Pods at any time: 4 (no surge allowed)
            # - Min available Pods at any time: 3 (1 can be unavailable)
            # - Total steps: 8 (4 kills + 4 creates)
          difficulty: 2
        - id: v3
          title: "Predict Rollout: 4 Replicas, maxSurge=2, maxUnavailable=1"
          description: >-
            A Deployment has <code>4</code> replicas running v1. A rolling update to v2 starts with
            <code>maxSurge: 2</code> and <code>maxUnavailable: 1</code>. What is the maximum total Pods?
            The minimum available? How does the rollout progress?
          functionSignature: "Rolling update step-by-step"
          testCases:
            - input: "Maximum total Pods"
              output: "6 (4 + maxSurge 2)"
            - input: "Minimum available Pods"
              output: "3 (4 - maxUnavailable 1)"
            - input: "Step 1"
              output: "Kill 1 old, create 2 new simultaneously  3 v1, 2 v2, total=5"
          hints:
            - title: "Think about it"
              content: >-
                With both maxSurge and maxUnavailable > 0, Kubernetes can simultaneously create new Pods and
                kill old ones. This makes the rollout faster but uses more resources.
            - title: "Hint"
              content: >-
                Max total = replicas + maxSurge = 6. Min available = replicas - maxUnavailable = 3. Kubernetes
                can create up to 2 extra Pods and kill up to 1 at the same time.
            - title: "Pattern"
              content: |-
                <pre>Max Pods = 4 + 2 = 6
                Min Available = 4 - 1 = 3
                Kubernetes can create and kill simultaneously,
                making the rollout faster than serial approaches.</pre>
          solution: |-
            # Rolling update progression: 4 replicas, maxSurge=2, maxUnavailable=1
            #
            # Start:   [v1] [v1] [v1] [v1]               4 v1, 0 v2, total=4
            # Step 1:  [] [v1] [v1] [v1] [v2] [v2]    3 v1, 2 v2, total=5
            #          (kill 1 old + create 2 new simultaneously)
            # Step 2:  [v2] [] [v1] [v1] [v2] [v2]    2 v1, 3 v2, total=5
            #          (kill 1 old, 1 new becomes Ready)
            # Step 3:  [v2] [v2] [] [v1] [v2] [v2]    1 v1, 4 v2, total=5
            #          (kill 1 old, another new Ready)
            # Step 4:  [v2] [v2] [v2] [] [v2]         0 v1, 4 v2, total=4
            #          (kill last old, scale down surge)
            # Done:    [v2] [v2] [v2] [v2]               0 v1, 4 v2, total=4
            #
            # Key constraints:
            # - Max total Pods at any time: 6 (replicas + maxSurge)
            # - Min available Pods at any time: 3 (replicas - maxUnavailable)
            # - Rollout is faster due to parallel create/kill
          difficulty: 3
        - id: v4
          title: "Predict Rollout: 6 Replicas, maxSurge=50%, maxUnavailable=0"
          description: >-
            A Deployment has <code>6</code> replicas running v1. A rolling update to v2 starts with
            <code>maxSurge: "50%"</code> and <code>maxUnavailable: 0</code>. Calculate the max Pods from the
            percentage and describe the rollout behavior.
          functionSignature: "Percentage-based rolling update"
          testCases:
            - input: "maxSurge in absolute Pods (50% of 6)"
              output: "3 (ceil of 6 * 0.50)"
            - input: "Maximum total Pods"
              output: "9 (6 + 3)"
            - input: "Minimum available Pods"
              output: "6 (maxUnavailable=0, all must stay available)"
          hints:
            - title: "Think about it"
              content: >-
                Percentage values are converted to absolute numbers. maxSurge rounds up (ceil), maxUnavailable
                also rounds up. 50% of 6 = 3.
            - title: "Hint"
              content: >-
                With 3 surge capacity and 0 unavailable, Kubernetes creates 3 new Pods first (total=9), then
                kills 3 old Pods as new ones become Ready.
            - title: "Pattern"
              content: |-
                <pre>maxSurge = ceil(6 * 0.50) = 3
                maxUnavailable = 0
                Max total = 6 + 3 = 9
                Min available = 6 - 0 = 6
                Creates 3 new Pods, then kills 3 old, then creates 3, kills 3</pre>
          solution: |-
            # Rolling update: 6 replicas, maxSurge=50%, maxUnavailable=0
            #
            # Calculation: maxSurge = ceil(6 * 0.50) = 3 extra Pods allowed
            #
            # Start:   [v1] [v1] [v1] [v1] [v1] [v1]                   6 v1, total=6
            # Step 1:  [v1] [v1] [v1] [v1] [v1] [v1] [v2] [v2] [v2]   6 v1, 3 v2, total=9
            #          (create 3 new Pods at once)
            # Step 2:  [] [] [] [v1] [v1] [v1] [v2] [v2] [v2]   3 v1, 3 v2, total=6
            #          (3 new Ready, kill 3 old)
            # Step 3:  [v2] [v2] [v2] [v1] [v1] [v1] [v2] [v2] [v2]   3 v1, 6 v2, total=9
            #          (create 3 more new Pods)
            # Step 4:  [v2] [v2] [v2] [] [] [] [v2] [v2] [v2]   0 v1, 6 v2, total=6
            #          (kill remaining 3 old Pods)
            # Done:    [v2] [v2] [v2] [v2] [v2] [v2]                   6 v2, total=6
            #
            # Key: 50% surge means half the fleet is replaced in each wave.
            # The rollout completes in ~2 waves instead of 6 serial steps.
          difficulty: 2
        - id: v5
          title: "Predict Rollout: 5 Replicas, maxSurge=25%, maxUnavailable=25%"
          description: >-
            A Deployment has <code>5</code> replicas running v1. A rolling update to v2 starts with
            <code>maxSurge: "25%"</code> and <code>maxUnavailable: "25%"</code> (the Kubernetes defaults).
            Calculate the absolute values from percentages and predict the maximum and minimum Pod counts.
          functionSignature: "Default Kubernetes rolling update"
          testCases:
            - input: "maxSurge absolute (25% of 5, rounded up)"
              output: "2 (ceil of 1.25)"
            - input: "maxUnavailable absolute (25% of 5, rounded up)"
              output: "2 (ceil of 1.25)"
            - input: "Maximum total Pods"
              output: "7 (5 + 2)"
            - input: "Minimum available Pods"
              output: "3 (5 - 2)"
          hints:
            - title: "Think about it"
              content: >-
                Both maxSurge and maxUnavailable round up when converting from percentage. 25% of 5 = 1.25,
                which rounds up to 2.
            - title: "Hint"
              content: >-
                Max total = 5 + ceil(5 * 0.25) = 5 + 2 = 7. Min available = 5 - ceil(5 * 0.25) = 5 - 2 = 3.
                Kubernetes can simultaneously have 2 extra Pods and 2 old Pods terminating.
            - title: "Pattern"
              content: |-
                <pre>maxSurge = ceil(5 * 0.25) = ceil(1.25) = 2
                maxUnavailable = ceil(5 * 0.25) = ceil(1.25) = 2
                Max total = 5 + 2 = 7
                Min available = 5 - 2 = 3</pre>
          solution: |-
            # Rolling update: 5 replicas, maxSurge=25%, maxUnavailable=25%
            #
            # Calculations:
            # maxSurge = ceil(5 * 0.25) = ceil(1.25) = 2
            # maxUnavailable = ceil(5 * 0.25) = ceil(1.25) = 2
            #
            # Start:   [v1] [v1] [v1] [v1] [v1]               5 v1, 0 v2, total=5
            # Step 1:  [] [] [v1] [v1] [v1] [v2] [v2]    3 v1, 2 v2, total=5
            #          (kill 2 old + create 2 new simultaneously)
            # Step 2:  [v2] [v2] [] [] [v1] [v2] [v2]    1 v1, 4 v2, total=5
            #          (2 new Ready, kill 2 more old, create 1 new)
            # Step 3:  [v2] [v2] [v2] [v2] [] [v2]         0 v1, 5 v2, total=5
            #          (kill last old, new becomes Ready)
            # Done:    [v2] [v2] [v2] [v2] [v2]               5 v2, total=5
            #
            # Key constraints:
            # - Max total Pods at any time: 7 (5 + 2)
            # - Min available Pods at any time: 3 (5 - 2)
            # - Faster than serial updates due to parallel operations
          difficulty: 2
        - id: v6
          title: "Invalid Configuration: maxSurge=0, maxUnavailable=0"
          description: >-
            Explain why a rolling update configuration with <code>maxSurge: 0</code> and
            <code>maxUnavailable: 0</code> is invalid. What error would Kubernetes return? Then write a
            corrected configuration for <code>4</code> replicas that uses no surge but allows one Pod
            to be unavailable.
          functionSignature: "Invalid config + correction"
          testCases:
            - input: "Why is maxSurge=0 + maxUnavailable=0 invalid?"
              output: "The rollout can never make progress: it cannot create new Pods (no surge) and cannot remove old ones (none unavailable)"
            - input: "Kubernetes error"
              output: "Invalid value: intstr.IntOrString{Type:0, IntVal:0, StrVal:\"\"}: may not be 0 when maxSurge is 0"
            - input: "Corrected configuration"
              output: "maxSurge: 0, maxUnavailable: 1"
          hints:
            - title: "Think about it"
              content: >-
                For a rollout to progress, it must either create a new Pod (needs surge > 0) OR kill an old Pod
                (needs unavailable > 0). If both are zero, it is deadlocked.
            - title: "Hint"
              content: >-
                At least one of maxSurge or maxUnavailable must be greater than 0. The safest minimal fix is
                <code>maxSurge: 0, maxUnavailable: 1</code> or <code>maxSurge: 1, maxUnavailable: 0</code>.
            - title: "Pattern"
              content: |-
                <pre># INVALID  rollout cannot progress
                maxSurge: 0
                maxUnavailable: 0

                # VALID  kill one old, create one new
                maxSurge: 0
                maxUnavailable: 1</pre>
          solution: |-
            # INVALID configuration (Kubernetes rejects this):
            # strategy:
            #   type: RollingUpdate
            #   rollingUpdate:
            #     maxSurge: 0
            #     maxUnavailable: 0
            #
            # Error: "may not be 0 when maxSurge is 0"
            # Reason: the rollout is deadlocked  it cannot create extra Pods
            # and cannot remove existing Pods, so it can never make progress.

            # Corrected configuration:
            apiVersion: apps/v1
            kind: Deployment
            metadata:
              name: app
            spec:
              replicas: 4
              strategy:
                type: RollingUpdate
                rollingUpdate:
                  maxSurge: 0
                  maxUnavailable: 1
              selector:
                matchLabels:
                  app: app
              template:
                metadata:
                  labels:
                    app: app
                spec:
                  containers:
                  - name: app
                    image: app:2.0
                    ports:
                    - containerPort: 8080
          difficulty: 3
        - id: v7
          title: "Predict Rollout: 10 Replicas, maxSurge=100%, maxUnavailable=0"
          description: >-
            A Deployment has <code>10</code> replicas running v1. A rolling update to v2 starts with
            <code>maxSurge: "100%"</code> and <code>maxUnavailable: 0</code>. How many Pods exist at peak?
            Describe how this behaves like a blue-green deployment.
          functionSignature: "Blue-green-like rolling update"
          testCases:
            - input: "Maximum total Pods at peak"
              output: "20 (10 old + 10 new)"
            - input: "Minimum available Pods"
              output: "10 (maxUnavailable=0, all must stay available)"
            - input: "How is this like blue-green?"
              output: "All new Pods are created before any old Pods are terminated"
          hints:
            - title: "Think about it"
              content: >-
                With 100% surge and 0 unavailable, Kubernetes creates all 10 new Pods first (reaching 20
                total), then kills all 10 old Pods. This is essentially blue-green within a single Deployment.
            - title: "Hint"
              content: >-
                The key difference from actual blue-green: traffic gradually shifts as new Pods become Ready
                and old Pods are terminated. There is no instant cutover with a Service selector switch.
            - title: "Pattern"
              content: |-
                <pre>maxSurge = 10 (100% of 10)
                Max total = 10 + 10 = 20 (peak)
                Step 1: Create all 10 v2 Pods  total=20
                Step 2: Kill all 10 v1 Pods  total=10
                Resources: doubles during the transition</pre>
          solution: |-
            # Rolling update: 10 replicas, maxSurge=100%, maxUnavailable=0
            #
            # maxSurge = 10 (100% of 10)
            #
            # Start:   [v1]*10                                10 v1, total=10
            # Step 1:  [v1]*10 [v2]*10                        10 v1, 10 v2, total=20
            #          (all 10 new Pods created at once)
            # Step 2:  [v2]*10                                0 v1, 10 v2, total=10
            #          (all 10 v2 Ready, kill all 10 v1)
            # Done:    [v2]*10                                10 v2, total=10
            #
            # This behaves like blue-green within a single Deployment:
            # - All new Pods are created before old Pods are removed
            # - Doubles resource usage at peak (20 Pods)
            # - No instant cutover (traffic shifts gradually, not via selector)
            # - Rollback is still "kubectl rollout undo" (not instant)
          difficulty: 3
        - id: v8
          title: "Predict Rollout: 8 Replicas, maxSurge=3, maxUnavailable=2"
          description: >-
            A Deployment has <code>8</code> replicas running v1. A rolling update to v2 starts with
            <code>maxSurge: 3</code> and <code>maxUnavailable: 2</code>. Calculate the max total, min
            available, and explain why this configuration results in a very fast rollout.
          functionSignature: "Fast aggressive rolling update"
          testCases:
            - input: "Maximum total Pods"
              output: "11 (8 + 3)"
            - input: "Minimum available Pods"
              output: "6 (8 - 2)"
            - input: "How many Pods change in the first step?"
              output: "Up to 5 (kill 2 old + create 3 new simultaneously)"
          hints:
            - title: "Think about it"
              content: >-
                With both high maxSurge and maxUnavailable, Kubernetes can create many new Pods and kill many
                old Pods in parallel. This is the fastest rolling update at the cost of resources and temporary
                reduced capacity.
            - title: "Hint"
              content: >-
                In the first step, Kubernetes can kill 2 old Pods (maxUnavailable) and create 3 new Pods
                (maxSurge) at the same time. That is 5 Pods changing in one step.
            - title: "Pattern"
              content: |-
                <pre>Max total = 8 + 3 = 11
                Min available = 8 - 2 = 6
                First step: kill 2 + create 3 = 5 Pods changing
                This aggressive config finishes the rollout very quickly.</pre>
          solution: |-
            # Rolling update: 8 replicas, maxSurge=3, maxUnavailable=2
            #
            # Max total Pods = 8 + 3 = 11
            # Min available Pods = 8 - 2 = 6
            #
            # Start:   [v1]*8                                   8 v1, 0 v2, total=8
            # Step 1:  [][][v1]*6 [v2][v2][v2]             6 v1, 3 v2, total=9
            #          (kill 2 old + create 3 new simultaneously)
            # Step 2:  [v2]*3 [][][v1]*4 [v2]*3            4 v1, 6 v2, total=10
            #          (3 new Ready, kill 2 more old, create 2 more new)
            # Step 3:  [v2]*6 [][][v2]*2                   0 v1, 8 v2, total=8
            #          (remaining old killed, new Pods fill in)
            # Done:    [v2]*8                                   8 v2, total=8
            #
            # This aggressive config finishes in ~3 steps instead of 8 serial steps.
            # Trade-off: temporarily uses up to 11 Pods and drops to 6 available.
          difficulty: 3
